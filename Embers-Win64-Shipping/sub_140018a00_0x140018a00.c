// 函数: sub_140018a00
// 地址: 0x140018a00
// 来自: E:\Embers\Embers\Binaries\Win64\Embers-Win64-Shipping.exe

int32_t var_a8[0x4] = arg5
float var_d8[0x4] = arg3[0].o
int32_t zmm0[0x8]
zmm0[0].o = arg1[0xe]
double zmm1[0x4]
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xe4))
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
double zmm3[0x4]
zmm3[0].o = _mm_broadcast_ss(*(arg1 + 0xec))
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
zmm1[0].o = _mm_permute_pd(zmm1[0].o, 1)
double zmm4[0x4]
zmm4[0].o = zmm1[0].o f* *(arg1 + 0xe8)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x88)
float temp0_9[0x4] = _mm_permute_ps(zmm1[0].o, 0xd8)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_9)
zmm3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(temp0_9, zmm3[0].o)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x4e), zmm0[0].o, 0xc)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0x78)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm4[0].o, 0x1c)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, arg3[0].o, 0x60)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
float zmm9[0x4] = data_142d3f670
zmm4[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm9, zmm0[0].o)
float zmm5[0x4] = arg1[6].d
int32_t temp0_19[0x4] = __vxorps_xmmdq_xmmdq_xmmdq(arg5, arg5)
float zmm6[0x8]
zmm6[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(temp0_19, *(arg1 + 0x64), 0x10)
float temp0_21[0x4] = __vinsertps_xmmdq_xmmdq_memd_immb(temp0_19, *(arg1 + 0x68), 0x20)
float zmm10[0x4] = *(arg1 + 0x6c)
arg3[0].o = _mm_permute_ps(zmm4[0].o, 0xc0)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm5, arg3[0].o)
zmm0[0].o = _mm_permute_ps(zmm3[0].o, 0xea)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm0[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = _mm_permute_ps(zmm1[0].o, 0xd5)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_21, arg3[0].o)
float zmm12[0x8]
zmm12[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
arg3[0].o = _mm_permute_ps(zmm1[0].o, 0xea)
float temp0_31[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm5, arg3[0].o)
arg3[0].o = _mm_permute_ps(zmm4[0].o, 0xd5)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, arg3[0].o)
float temp0_34[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(temp0_31, arg3[0].o)
arg3[0].o = _mm_permute_ps(zmm3[0].o, 0xc0)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_21, arg3[0].o)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_34)
zmm0[0].o = _mm_permute_ps(zmm3[0].o, 0xd5)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm5, zmm0[0].o)
float temp0_40[0x4] = _mm_permute_ps(zmm1[0].o, 0xc0)
float temp0_41[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_40)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_41)
float temp0_44[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_21, _mm_permute_ps(zmm4[0].o, 0xea))
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_44)
float temp0_47[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm1[0].o, 0x9c), zmm3[0].o, 0x60)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm3[0].o, 0x8c)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm1[0].o, 0x20)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x4e)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm3[0].o, 0x14)
zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm4[0].o, 4)
zmm3[0].o = _mm_permute_ps(zmm12[0].o, 0xc0)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_47, zmm3[0].o)
zmm4[0].o = _mm_permute_ps(zmm12[0].o, 0xd5)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm4[0].o)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm4[0].o)
zmm4[0].o = _mm_permute_ps(zmm12[0].o, 0xea)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm4[0].o)
zmm12[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm3[0].o)
zmm3[0].o = _mm_permute_ps(arg3[0].o, 0xc0)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_47, zmm3[0].o)
zmm4[0].o = _mm_permute_ps(arg3[0].o, 0xd5)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm4[0].o)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm4[0].o)
arg3[0].o = _mm_permute_ps(arg3[0].o, 0xea)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
float temp0_68[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
arg3[0].o = _mm_permute_ps(zmm0[0].o, 0xc0)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_47, arg3[0].o)
zmm3[0].o = _mm_permute_ps(zmm0[0].o, 0xd5)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm3[0].o)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xea)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
float temp0_76[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
zmm0[0].o = arg1[0xf]
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xf4))
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
zmm3[0].o = _mm_broadcast_ss(*(arg1 + 0xfc))
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
zmm1[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm4[0].o = zmm1[0].o f* *(arg1 + 0xf8)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x88)
float temp0_86[0x4] = _mm_permute_ps(zmm1[0].o, 0xd8)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_86)
zmm3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(temp0_86, zmm3[0].o)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x4e), zmm0[0].o, 0xc)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0x78)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm4[0].o, 0x1c)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, arg3[0].o, 0x60)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm9, zmm0[0].o)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(temp0_19, arg1[7].d, 0x10)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(temp0_19, *(arg1 + 0x74), 0x20)
float temp0_99[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm10, _mm_permute_ps(arg3[0].o, 0xc0))
zmm6[0].o = _mm_permute_ps(zmm3[0].o, 0xea)
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm6[0].o)
float temp0_102[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_99)
zmm6[0].o = _mm_permute_ps(zmm1[0].o, 0xd5)
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm6[0].o)
float temp0_105[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_102)
zmm6[0].o = _mm_permute_ps(zmm1[0].o, 0xea)
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm10, zmm6[0].o)
float temp0_108[0x4] = _mm_permute_ps(arg3[0].o, 0xd5)
float temp0_109[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_108)
zmm6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_109)
float temp0_111[0x4] = _mm_permute_ps(zmm3[0].o, 0xc0)
zmm6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(__vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_111), zmm6[0].o)
float temp0_115[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm10, _mm_permute_ps(zmm3[0].o, 0xd5))
float temp0_116[0x4] = _mm_permute_ps(zmm1[0].o, 0xc0)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_116)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_115, zmm0[0].o)
float temp0_119[0x4] = _mm_permute_ps(arg3[0].o, 0xea)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_119)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x9c)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm3[0].o, 0x60)
float temp0_125[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x8c), zmm1[0].o, 0x20)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x4e)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm3[0].o, 0x14)
zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg3[0].o, 4)
arg3[0].o = _mm_permute_ps(temp0_105, 0xc0)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
zmm3[0].o = _mm_permute_ps(temp0_105, 0xd5)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_125, zmm3[0].o)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm3[0].o = _mm_permute_ps(temp0_105, 0xea)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
arg5 = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
arg3[0].o = _mm_permute_ps(zmm6[0].o, 0xc0)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
zmm3[0].o = _mm_permute_ps(zmm6[0].o, 0xd5)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_125, zmm3[0].o)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm3[0].o = _mm_permute_ps(zmm6[0].o, 0xea)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
float temp0_144[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
arg3[0].o = _mm_permute_ps(zmm0[0].o, 0xc0)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
zmm3[0].o = _mm_permute_ps(zmm0[0].o, 0xd5)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_125, zmm3[0].o)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xea)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
float temp0_152[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
zmm0[0].o = __vmovsd_xmmdq_memq(arg1[8].q)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, *(arg1 + 0x88), 0x20)
zmm1[0].o = __vmovsd_xmmdq_memq(arg1[0xc].q)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, *(arg1 + 0xc8), 0x20)
zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm9 = data_142d3f780
arg3[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm3[0].o = __vxorpd_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm9)
zmm4[0].o = _mm_permute_ps(zmm3[0].o, 0x80)
float temp0_162[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(temp0_68, 0xc1), zmm4[0].o)
zmm6[0].o = _mm_permute_ps(zmm1[0].o, 0xd5)
float temp0_166[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(
    __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(temp0_76, 0xc1), zmm6[0].o), temp0_162)
float temp0_167[0x4] = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm1[0].o, 0x9c)
zmm0[0].o = __vxorps_xmmdq_xmmdq_xmmdq(temp0_167, zmm9)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm0[0].o, 0x20)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_166)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(__vmovshdup_xmmdq_xmmdq(temp0_76), temp0_68, 0x68), 
    zmm4[0].o)
zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(
    __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(temp0_76, 0xda), zmm6[0].o), zmm4[0].o)
zmm5 = __vxorps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm9)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(temp0_167, zmm5, 0x10)
zmm6[0].o = zmm6[0].q | zmm1[0] << 0x40
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm4[0].o)
float temp0_181[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm4[0].o)
zmm4[0].o = _mm_permute_ps(zmm1[0].o, 0x4a)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm0[0].o, 0x20)
zmm6[0].o = _mm_permute_ps(zmm12[0].o, 0xc0)
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm4[0].o)
float temp0_187[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_76, 
    __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_68, temp0_76, 0x30), 0x80)
zmm3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm5, zmm1[0].o, 0x40)
float temp0_189[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_187, zmm3[0].o)
zmm6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_189)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm0[0].o, 0x10)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm0[0].o, 0x20)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm6[0].o)
arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_76, temp0_68, 0xc)
arg3[0].o = _mm_permute_ps(arg3[0].o, 0x78)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
arg3[0].o = _mm_permute_ps(temp0_76, 0x46)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, temp0_68, 0x68)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm6[0].o = *(arg1 + 0x78)
float temp0_200[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_181)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm3[0].o)
zmm4[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm5, zmm1[0].o, 0)
zmm1[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm1[0].o, 0xc8)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm6[0].o, *(arg1 + 0x78), 0x20)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0x8c))
zmm4[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, *(arg1 + 0x94), 0x20)
float temp0_209[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
zmm1[0].o = *(arg1 + 0xd4)
zmm0[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0xcc))
float var_1d8[0x4] = zmm1[0].o
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x20)
zmm3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm0[0].o)
zmm4[0].o = _mm_permute_pd(zmm3[0].o, 1)
zmm0[0].o = __vxorpd_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm9)
float temp0_215[0x4] = _mm_permute_ps(zmm0[0].o, 0x80)
zmm6[0].o = _mm_permute_ps(temp0_144, 0xc1)
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_215)
float temp0_218[0x4] = _mm_permute_ps(zmm3[0].o, 0xd5)
arg3[0].o = _mm_permute_ps(temp0_152, 0xc1)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_218)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm6[0].o)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm3[0].o, 0x9c)
zmm6[0].o = __vmovshdup_xmmdq_xmmdq(zmm3[0].o)
zmm1[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm9)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x20)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = __vmovshdup_xmmdq_xmmdq(temp0_152)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, temp0_144, 0x68)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_215)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(
    __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(temp0_152, 0xda), temp0_218), arg3[0].o)
zmm5 = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm9)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm5, 0x10)
zmm6[0].o = zmm6[0].q | zmm3[0] << 0x40
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, arg3[0].o)
float temp0_236[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = _mm_permute_ps(zmm3[0].o, 0x4a)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x20)
int32_t var_1c8[0x4] = arg5
zmm6[0].o = _mm_permute_ps(arg5, 0xc0)
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, arg3[0].o)
float temp0_242[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_152, 
    __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_144, temp0_152, 0x30), 0x80)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm5, zmm3[0].o, 0x40)
float temp0_244[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_242, zmm0[0].o)
zmm6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_244)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm1[0].o, 0x10)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm1[0].o, 0x20)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm6[0].o)
zmm4[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_152, temp0_144, 0xc)
zmm4[0].o = _mm_permute_ps(zmm4[0].o, 0x78)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
zmm4[0].o = _mm_permute_ps(temp0_152, 0x46)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, temp0_144, 0x68)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm0[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm5, zmm3[0].o, 0)
arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0xc8)
float zmm7[0x4] = *(arg1 + 0x7c)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm7, temp0_236)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm7, zmm7, 0x20)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
zmm1[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_200, temp0_209, 5)
zmm1[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, temp0_209, 0xd8)
arg3[0].o = _mm_permute_pd(temp0_200, 1)
arg3[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_209, arg3[0].o, 1)
zmm4[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm0[0].o, 5)
zmm4[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm0[0].o, 0xd8)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm4[0].o)
zmm4[0].o = _mm_permute_pd(zmm3[0].o, 1)
zmm0[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 1)
zmm6 = *arg4
int32_t temp0_272 = _mm256_movemask_ps(zmm6)
int32_t temp0_273 = __vextractps_gpr32_xmmdq_immb(zmm12[0].o, 1)
int128_t var_1b8 = zmm12[0].o
int32_t temp0_274 = __vextractps_gpr32_xmmdq_immb(zmm12[0].o, 2)
int32_t temp0_275 = __vextractps_gpr32_xmmdq_immb(temp0_68, 2)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
float temp0_277[0x4] = __vmovshdup_xmmdq_xmmdq(temp0_68)
int32_t temp0_278 = __vextractps_gpr32_xmmdq_immb(zmm1[0].o, 0)
int32_t temp0_279 = __vextractps_gpr32_xmmdq_immb(zmm1[0].o, 1)
int32_t temp0_280 = __vextractps_gpr32_xmmdq_immb(zmm1[0].o, 2)
int32_t temp0_281 = __vextractps_gpr32_xmmdq_immb(zmm0[0].o, 0)
int32_t temp0_282 = __vextractps_gpr32_xmmdq_immb(zmm0[0].o, 1)
int32_t temp0_283 = __vextractps_gpr32_xmmdq_immb(zmm0[0].o, 2)
zmm12[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_200, zmm3[0].o)
float temp0_285[0x4] = __vmovshdup_xmmdq_xmmdq(zmm12[0].o)
zmm0 = __vblendps_ymmqq_ymmqq_memqq_immb(zmm12, data_142fc9300, 0xf8)
zmm10 = _mm_permute_pd(zmm12[0].o, 1)
zmm0 = __vandps_ymmqq_ymmqq_memqq(zmm0, data_142fc9320)
float var_128[0x4] = zmm7
float var_138 = temp0_277[0]
float var_148[0x4] = zmm10
zmm0 = __vcmpps_ymmqq_ymmqq_memqq_immb(zmm0, data_142fc9340, 2)
float zmm11[0x4]
float zmm13[0x4]
float zmm14[0x4]

if (temp0_272 != 0xff)
    zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
    zmm1[0].o = __vpcmpeqd_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm3[0].o)
    arg3[0].o = _mm256_extractf128_ps(zmm6[0].o, 1)
    zmm3[0].o = __vpcmpeqd_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
    zmm4[0].o = _mm256_extractf128_ps(zmm0[0].o, 1)
    zmm3[0].o |= zmm4[0].o
    zmm0[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
    zmm0[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm3[0].o)
    zmm0[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
    char temp0_400 = __vpmovmskb_gpr32d_xmmdq(zmm0[0].o)
    arg5 = zx.o(temp0_278)
    zmm9 = zx.o(temp0_279)
    zmm0[0].o = zx.o(temp0_280)
    
    if (temp0_400 != 0xff)
    label_140019500:
        float temp0_428[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm10, zmm0[0].o, 0x2a)
        zmm14 = zx.o(temp0_281)
        zmm1[0].o = zx.o(temp0_282)
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm14, zmm1[0].o, 0x1c)
        zmm3[0].o = zmm10
        zmm11 = zx.o(temp0_283)
        float temp0_432[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(
            __vinsertps_xmmdq_xmmdq_xmmdq_immb(
                __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm12[0].o, zmm10, 0x10), zmm14, 0x20), 
            zmm11, 0x30)
        zmm6[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm9, 1f, 0x36)
        float temp0_434[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_432)
        zmm4[0].o = temp0_285
        zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(temp0_285, zmm1[0].o, 0x2a)
        float temp0_436[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg5, zmm0[0].o, 0x1c)
        zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_436)
        float temp0_438[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(temp0_434, zmm6[0].o)
        zmm6[0].o = _mm_permute_ps(temp0_438, 0)
        float var_158_2[0x4] = zmm6[0].o
        float temp0_440[0x4] = _mm_permute_ps(temp0_438, 0x55)
        zmm3[0].o = _mm_permute_ps(temp0_438, 0xaa)
        float temp0_442[0x4] = _mm_permute_ps(temp0_438, 0xff)
        zmm6[0].o = 0x3f800000
        float temp0_443[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(0x3f800000, zmm11, 0)
        int128_t var_178_2 = arg3[0].o
        float temp0_444[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_443, arg3[0].o)
        arg3[0].o = zmm3[0].o
        float var_1a8_2 = zmm14[0]
        zmm1[0].o = __vunpcklps_xmmdq_xmmdq_xmmdq(zmm14, zmm1[0].o)
        zmm7 = __vxorps_xmmdq_xmmdq_xmmdq(temp0_436, temp0_436)
        zmm1[0].o = zmm7[0].q | zmm1[0] << 0x40
        zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm7)
        zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(temp0_444, zmm1[0].o)
        float var_198_2 = zmm9[0]
        float temp0_450[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_428, 
            __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm9, zmm12[0].o, 0))
        float temp0_451[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, arg5, 0)
        float var_188_2[0x4] = zmm0[0].o
        float temp0_454[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(temp0_450, 
            __vmulps_xmmdq_xmmdq_xmmdq(temp0_451, 
                __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm12[0].o, 0xaa)))
        float temp0_455[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(var_158_2, temp0_442)
        zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_440, zmm3[0].o)
        zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_455, zmm0[0].o)
        float temp0_459[0x4] =
            __vmulps_xmmdq_xmmdq_xmmdq(temp0_454, _mm_permute_ps(zmm1[0].o, 0xd8))
        zmm3[0].o = _mm_permute_pd(temp0_459, 1)
        zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_459, zmm3[0].o)
        float temp0_462[0x4] = _mm_permute_ps(zmm3[0].o, 0x39)
        zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_462)
        float temp0_464[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm3[0].o)
        zmm0[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
        temp0_464 f- zmm0[0]
        
        if (temp0_464 f!= zmm0[0] || not(is_ordered.d(temp0_464, zmm0[0])))
            zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm12[0].o, arg5, 0x20)
            float temp0_467[0x4] = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, var_198_2, 0x30)
            zmm3[0].o = __vmovsldup_xmmdq_xmmdq(zmm12[0].o)
            zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, arg5, 0x30)
            zmm6[0].o = __vmovddup_xmmdq_xmmq(zmm1[0])
            zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm6[0].o)
            zmm6[0].o = _mm_permute_ps(zmm1[0].o, 0x20)
            zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_467, zmm6[0].o)
            zmm3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm3[0].o)
            zmm0[0].o = temp0_428
            zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
            arg5 = __vsubps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm3[0].o)
            zmm6[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm11, 1f, 0x36)
            zmm3[0].o = data_142d4cc30
            zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm11, 0x10)
            zmm4[0].o = _mm_permute_ps(temp0_454, 0x66)
            zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm4[0].o)
            zmm4[0].o = _mm_permute_ps(temp0_454, 0x33)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm4[0].o)
            zmm3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm3[0].o)
            arg3[0].o = var_178_2
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_440)
            zmm12[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm3[0].o)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, var_158_2)
            zmm6[0].o = _mm_permute_pd(temp0_454, 3)
            zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm6[0].o)
            arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, var_1a8_2, 0x1d)
            zmm7 = __vmovddup_xmmdq_xmmq(temp0_454[0].q)
            arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm7)
            arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, arg3[0].o)
            arg3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
            zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_467, temp0_442)
            zmm4[0].o = _mm_permute_ps(zmm1[0].o, 0xcc)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
            zmm0[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
            zmm6[0].o = __vblendps_xmmdq_xmmdq_memdq_immb(zmm0[0].o, var_188_2, 1)
            zmm6[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(
                __vblendps_xmmdq_xmmdq_memdq_immb(zmm0[0].o, var_148, 1), zmm6[0].o, 0x11)
            zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0x66)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm1[0].o)
            zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm1[0].o)
            zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm1[0].o)
            zmm1[0].o = data_142fc92f0
            zmm1[0].o = __vdivps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_464)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
            zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm12[0].o, zmm1[0].o)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg5, zmm1[0].o)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm1[0].o)
            zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x77)
            zmm6[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm3[0].o, 0x77)
            arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm3[0].o, 0x22)
        else
            arg3[0].o = data_142d4cc20
            zmm0[0].o = data_142d4cc30
        
        zmm12[0].o = var_1b8
        zmm13 = var_1c8
        zmm14 = var_1d8
        arg5 = __vmovshdup_xmmdq_xmmdq(zmm6[0].o)
        zmm9 = _mm_permute_pd(zmm6[0].o, 1)
        zmm10 = _mm_permute_ps(zmm6[0].o, 0xe7)
        zmm11 = __vmovshdup_xmmdq_xmmdq(arg3[0].o)
        zmm7 = _mm_permute_pd(arg3[0].o, 1)
        zmm1[0].o = _mm_permute_ps(arg3[0].o, 0xe7)
        zmm4[0].o = __vmovshdup_xmmdq_xmmdq(zmm0[0].o)
        zmm5 = _mm_permute_pd(zmm0[0].o, 1)
        zmm3[0].o = _mm_permute_ps(zmm0[0].o, 0xe7)
    else
        zmm1[0].o = zx.o(0)
        zmm3[0].o = __vpcmpeqd_xmmdq_xmmdq_xmmdq(zmm6[0].o, zx.o(0))
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg5, zmm9, 0x10)
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm0[0].o, 0x20)
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, 0x800000, 0x30)
        zmm4 = __vcmpps_ymmqq_ymmqq_memqq_immb(
            __vandps_ymmqq_ymmqq_memqq(_mm256_insertf128_ps(zmm4, _mm_permute_ps(0x800000, 0), 1), 
                data_142fc9320), 
            data_142fc9340, 2)
        arg3[0].o = __vpcmpeqd_xmmdq_xmmdq_xmmdq(arg3[0].o, zx.o(0))
        zmm5 = _mm256_extractf128_ps(zmm4[0].o, 1) | arg3[0].o
        zmm3[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm3[0].o)
        zmm3[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm5)
        zmm3[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
        
        if (__vpmovmskb_gpr32d_xmmdq(zmm3[0].o) != 0xff)
            goto label_140019500
        
        zmm3[0].o = zx.o(temp0_281)
        zmm4[0].o = zx.o(temp0_282)
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm4[0].o, 0x10)
        zmm4[0].o = zx.o(temp0_283)
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm4[0].o, 0x20)
        zmm4[0].o = 0x800000
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, 0x800000, 0x30)
        zmm4[0].o = _mm_permute_ps(0x800000, 0)
        zmm3 = __vcmpps_ymmqq_ymmqq_memqq_immb(
            __vandps_ymmqq_ymmqq_memqq(_mm256_insertf128_ps(zmm3, zmm4[0].o, 1), data_142fc9320), 
            data_142fc9340, 2)
        zmm1[0].o = __vpcmpeqd_xmmdq_xmmdq_xmmdq(zmm6[0].o, zx.o(0))
        zmm4[0].o = _mm256_extractf128_ps(zmm3[0].o, 1)
        arg3[0].o |= zmm4[0].o
        zmm1[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm1[0].o)
        zmm1[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
        zmm1[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
        
        if (__vpmovmskb_gpr32d_xmmdq(zmm1[0].o) != 0xff)
            goto label_140019500
        
        zmm5 = 0x3f800000
        zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
        zmm4[0].o = zx.o(0)
        zmm0[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
        zmm1[0].o = zx.o(0)
        zmm7 = __vxorps_xmmdq_xmmdq_xmmdq(zmm7, zmm7)
        zmm11 = 0x3f800000
        arg3[0].o = zx.o(0)
        zmm10 = __vxorps_xmmdq_xmmdq_xmmdq(zmm10, zmm10)
        zmm9 = __vxorps_xmmdq_xmmdq_xmmdq(zmm9, zmm9)
        arg5 = __vxorps_xmmdq_xmmdq_xmmdq(arg5, arg5)
        zmm6[0].o = 0x3f800000
        zmm12[0].o = var_1b8
        zmm13 = var_1c8
        zmm14 = var_1d8
    
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x10)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm5, 0x20)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm3[0].o, 0x30)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm11, 0x10)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm7, 0x20)
    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x30)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, arg5, 0x10)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm9, 0x20)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm10, 0x30)
    zmm3[0].o = _mm_broadcast_ss(*arg2)
    arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
    zmm3[0].o = _mm_broadcast_ss(arg2[1])
    zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
    zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm1[0].o)
    arg3[0].o = _mm_broadcast_ss(arg2[2])
    zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
    arg3[0].o = __vmovsd_xmmdq_memq(arg1[8].q)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(arg3[0].o, *(arg1 + 0x88), 0x20)
    zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
    zmm0[0].o = __vmovsd_xmmdq_memq(arg1[0xc].q)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, *(arg1 + 0xc8), 0x20)
    zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
    arg3[0].o = _mm_permute_ps(zmm1[0].o, 0xc9)
    zmm3[0].o = _mm_permute_ps(zmm4[0].o, 0xd2)
    arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
    zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xd2)
    zmm3[0].o = _mm_permute_ps(zmm4[0].o, 0xc9)
    zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm1[0].o)
    zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm1[0].o)
    arg3[0].o = zx.o(temp0_273)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm12[0].o, arg3[0].o, 0x10)
    zmm3[0].o = zx.o(temp0_274)
    float temp0_611[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x20)
    arg3[0].o = _mm_broadcast_ss(*(arg1 + 0x78))
    zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
    arg3[0].o = var_128
    arg3[0].o = __vxorps_xmmdq_xmmdq_memdq(arg3[0].o, data_142d3f780)
    arg3[0].o = _mm_permute_ps(arg3[0].o, 0xc0)
    arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
    zmm6[0].o = temp0_68
    zmm6[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm6[0].o, var_138, 0x10)
    zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zx.o(temp0_275), 0x20)
    float temp0_620[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_611, _mm_permute_ps(zmm1[0].o, 0xc0))
    float temp0_621[0x4] = _mm_permute_ps(zmm1[0].o, 0xd5)
    zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_621)
    zmm7 = __vmovsd_xmmdq_memq(*(arg1 + 0x8c))
    float temp0_624[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(temp0_620, zmm6[0].o)
    zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xea)
    zmm1[0].o = __vmulps_xmmdq_xmmdq_memdq(zmm1[0].o, temp0_76)
    arg5 = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_624)
    zmm5 = __vinsertps_xmmdq_xmmdq_memd_immb(zmm7, *(arg1 + 0x94), 0x20)
    zmm6[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0xcc))
    zmm7 = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm14, 0x20)
else
    char temp0_290 = _mm256_movemask_ps(zmm0)
    zmm14 = zx.o(temp0_278)
    zmm4[0].o = zx.o(temp0_279)
    arg3[0].o = zx.o(temp0_280)
    
    if (temp0_290 != 0xff)
    label_1400191ba:
        zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm10, arg3[0].o, 0x2a)
        float zmm15[0x4] = zx.o(temp0_281)
        zmm1[0].o = zx.o(temp0_282)
        zmm11 = arg3[0].o
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm15, zmm1[0].o, 0x1c)
        arg5 = zx.o(temp0_283)
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm12[0].o, zmm10, 0x10)
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm15, 0x20)
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, arg5, 0x30)
        zmm6[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm4[0].o, 1f, 0x36)
        zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm3[0].o)
        zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(temp0_285, zmm1[0].o, 0x2a)
        float temp0_315[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm14, zmm11, 0x1c)
        zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_315)
        zmm3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm6[0].o)
        zmm6[0].o = _mm_permute_ps(zmm3[0].o, 0)
        float var_188_1[0x4] = zmm6[0].o
        float temp0_319[0x4] = _mm_permute_ps(zmm3[0].o, 0x55)
        float temp0_320[0x4] = _mm_permute_ps(zmm3[0].o, 0xaa)
        zmm7 = zmm4[0].o
        zmm4[0].o = _mm_permute_ps(zmm3[0].o, 0xff)
        zmm10 = zmm14
        zmm14 = 0x3f800000
        zmm3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(0x3f800000, arg5, 0)
        int128_t var_178_1 = arg3[0].o
        zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
        float var_198_1 = zmm15[0]
        zmm1[0].o = __vunpcklps_xmmdq_xmmdq_xmmdq(zmm15, zmm1[0].o)
        arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
        zmm1[0].o = arg3[0].q | zmm1[0] << 0x40
        zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
        float temp0_327[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm1[0].o)
        float var_1a8_1 = zmm7[0]
        zmm1[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm7, zmm12[0].o, 0)
        int128_t var_158_1 = zmm0[0].o
        zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
        zmm3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_285, zmm10, 0)
        float temp0_331[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm11, zmm12[0].o, 0xaa)
        zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_331)
        zmm3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
        float var_168_1[0x4] = zmm4[0].o
        zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm4[0].o)
        float temp0_335[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_319, temp0_320)
        zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_335)
        float temp0_337[0x4] = _mm_permute_ps(temp0_327, 0xd8)
        float temp0_338[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_337)
        float temp0_340[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(temp0_338, _mm_permute_pd(temp0_338, 1))
        arg3[0].o = _mm_permute_ps(temp0_340, 0x39)
        arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_340, arg3[0].o)
        zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
        arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
        zmm1[0].o f- arg3[0]
        
        if (zmm1[0].o f!= arg3[0] || not(is_ordered.d(zmm1[0].o, arg3[0])))
            zmm4[0].o = temp0_319
            arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm12[0].o, zmm10, 0x20)
            float temp0_346[0x4] = __vinsertps_xmmdq_xmmdq_memd_immb(arg3[0].o, var_1a8_1, 0x30)
            zmm6[0].o = __vmovsldup_xmmdq_xmmdq(zmm12[0].o)
            zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm10, 0x30)
            zmm6[0].o = __vmovddup_xmmdq_xmmq(temp0_327[0].q)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm6[0].o)
            zmm6[0].o = _mm_permute_ps(temp0_327, 0x20)
            zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_346, zmm6[0].o)
            zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm0[0].o)
            arg3[0].o = var_158_1
            zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_320)
            float temp0_355[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm0[0].o)
            zmm6[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(arg5, 1f, 0x36)
            float temp0_359[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(
                __vinsertps_xmmdq_xmmdq_xmmdq_immb(data_142d4cc30, arg5, 0x10), 
                _mm_permute_ps(zmm3[0].o, 0x66))
            float temp0_360[0x4] = _mm_permute_ps(zmm3[0].o, 0x33)
            float temp0_362[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(
                __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_360), temp0_359)
            zmm0[0].o = var_178_1
            float temp0_364[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(
                __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_319), temp0_362)
            zmm6[0].o = __vmulps_xmmdq_xmmdq_memdq(zmm6[0].o, var_188_1)
            zmm7 = _mm_permute_pd(zmm3[0].o, 3)
            float temp0_367[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm7)
            zmm4[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, var_198_1, 0x1d)
            zmm3[0].o = __vmovddup_xmmdq_xmmq(zmm3[0])
            zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm3[0].o)
            zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_367, zmm3[0].o)
            zmm3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm3[0].o)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_memdq(temp0_346, var_168_1)
            zmm4[0].o = _mm_permute_ps(temp0_327, 0xcc)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
            arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
            zmm6[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm11, 1)
            zmm6[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(
                __vblendps_xmmdq_xmmdq_memdq_immb(arg3[0].o, var_148, 1), zmm6[0].o, 0x11)
            float temp0_380[0x4] = _mm_permute_ps(temp0_327, 0x66)
            zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_380)
            zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm6[0].o)
            arg3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
            zmm4[0].o = data_142fc92f0
            zmm1[0].o = __vdivps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm1[0].o)
            arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm1[0].o)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_364, zmm1[0].o)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_355, zmm1[0].o)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm1[0].o)
            zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x77)
            zmm14 = __vshufps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm4[0].o, 0x77)
            arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm4[0].o, 0x22)
        else
            arg3[0].o = data_142d4cc20
            zmm0[0].o = data_142d4cc30
        
        zmm12[0].o = var_1b8
        zmm13 = var_1c8
        zmm10 = var_1d8
        arg5 = __vmovshdup_xmmdq_xmmdq(zmm14)
        zmm9 = _mm_permute_pd(zmm14, 1)
        zmm6[0].o = _mm_permute_ps(zmm14, 0xe7)
        zmm11 = __vmovshdup_xmmdq_xmmdq(arg3[0].o)
        zmm7 = _mm_permute_pd(arg3[0].o, 1)
        zmm1[0].o = _mm_permute_ps(arg3[0].o, 0xe7)
        zmm4[0].o = __vmovshdup_xmmdq_xmmdq(zmm0[0].o)
        zmm5 = _mm_permute_pd(zmm0[0].o, 1)
        zmm3[0].o = _mm_permute_ps(zmm0[0].o, 0xe7)
    else
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm14, zmm4[0].o, 0x10)
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg3[0].o, 0x20)
        zmm3[0].o = 0x800000
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, 0x800000, 0x30)
        zmm3[0].o = _mm_permute_ps(0x800000, 0)
        zmm1 = __vcmpps_ymmqq_ymmqq_memqq_immb(
            __vandps_ymmqq_ymmqq_memqq(_mm256_insertf128_ps(zmm1, zmm3[0].o, 1), data_142fc9320), 
            data_142fc9340, 2)
        
        if (_mm256_movemask_ps(zmm1) != 0xff)
            goto label_1400191ba
        
        zmm1[0].o = zx.o(temp0_281)
        zmm3[0].o = zx.o(temp0_282)
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm3[0].o, 0x10)
        zmm3[0].o = zx.o(temp0_283)
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm3[0].o, 0x20)
        zmm3[0].o = 0x800000
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, 0x800000, 0x30)
        zmm3[0].o = _mm_permute_ps(0x800000, 0)
        zmm1 = __vcmpps_ymmqq_ymmqq_memqq_immb(
            __vandps_ymmqq_ymmqq_memqq(_mm256_insertf128_ps(zmm1, zmm3[0].o, 1), data_142fc9320), 
            data_142fc9340, 2)
        
        if (_mm256_movemask_ps(zmm1) != 0xff)
            goto label_1400191ba
        
        zmm5 = 0x3f800000
        zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
        zmm4[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm4[0].o)
        zmm0[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
        zmm1[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm1[0].o)
        zmm7 = __vxorps_xmmdq_xmmdq_xmmdq(zmm7, zmm7)
        zmm11 = 0x3f800000
        arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
        zmm6[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm6[0].o)
        zmm9 = __vxorps_xmmdq_xmmdq_xmmdq(temp0_236, temp0_236)
        arg5 = __vxorps_xmmdq_xmmdq_xmmdq(arg5, arg5)
        zmm14 = 0x3f800000
        zmm12[0].o = var_1b8
        zmm13 = var_1c8
        zmm10 = var_1d8
    
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x10)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm5, 0x20)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm3[0].o, 0x30)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm11, 0x10)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm7, 0x20)
    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x30)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm14, arg5, 0x10)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm9, 0x20)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm6[0].o, 0x30)
    zmm3[0].o = _mm_broadcast_ss(*arg2)
    arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
    zmm3[0].o = _mm_broadcast_ss(arg2[1])
    zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
    zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm1[0].o)
    arg3[0].o = _mm_broadcast_ss(arg2[2])
    zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
    arg3[0].o = __vmovsd_xmmdq_memq(arg1[8].q)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(arg3[0].o, *(arg1 + 0x88), 0x20)
    zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
    zmm0[0].o = __vmovsd_xmmdq_memq(arg1[0xc].q)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, *(arg1 + 0xc8), 0x20)
    zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
    arg3[0].o = _mm_permute_ps(zmm1[0].o, 0xc9)
    zmm3[0].o = _mm_permute_ps(zmm4[0].o, 0xd2)
    arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
    zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xd2)
    zmm3[0].o = _mm_permute_ps(zmm4[0].o, 0xc9)
    zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm1[0].o)
    zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm1[0].o)
    arg3[0].o = zx.o(temp0_273)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm12[0].o, arg3[0].o, 0x10)
    zmm3[0].o = zx.o(temp0_274)
    float temp0_552[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x20)
    arg3[0].o = _mm_broadcast_ss(*(arg1 + 0x78))
    zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
    arg3[0].o = var_128
    arg3[0].o = __vxorps_xmmdq_xmmdq_memdq(arg3[0].o, data_142d3f780)
    arg3[0].o = _mm_permute_ps(arg3[0].o, 0xc0)
    arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
    zmm6[0].o = temp0_68
    zmm6[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm6[0].o, var_138, 0x10)
    zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zx.o(temp0_275), 0x20)
    float temp0_561[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_552, _mm_permute_ps(zmm1[0].o, 0xc0))
    float temp0_562[0x4] = _mm_permute_ps(zmm1[0].o, 0xd5)
    zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, temp0_562)
    zmm7 = __vmovsd_xmmdq_memq(*(arg1 + 0x8c))
    float temp0_565[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(temp0_561, zmm6[0].o)
    zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xea)
    zmm1[0].o = __vmulps_xmmdq_xmmdq_memdq(zmm1[0].o, temp0_76)
    arg5 = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_565)
    zmm5 = __vinsertps_xmmdq_xmmdq_memd_immb(zmm7, *(arg1 + 0x94), 0x20)
    zmm6[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0xcc))
    zmm7 = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm10, 0x20)
float temp0_631[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(zmm5, zmm7)
float temp0_632[0x4] = _mm_permute_ps(temp0_631, 0xc9)
zmm4[0].o = __vxorps_xmmdq_xmmdq_memdq(zmm4[0].o, data_142d3f780)
zmm1[0].o = _mm_permute_ps(zmm4[0].o, 0xd2)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_632)
float temp0_636[0x4] = _mm_permute_ps(temp0_631, 0xd2)
zmm4[0].o = _mm_permute_ps(zmm4[0].o, 0xc9)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_636)
zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm4[0].o)
zmm4[0].o = _mm_permute_ps(zmm1[0].o, 0xc0)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm13, zmm4[0].o)
float temp0_643[0x4] = __vmulps_xmmdq_xmmdq_memdq(_mm_permute_ps(zmm1[0].o, 0xd5), temp0_144)
zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_643)
float temp0_645[0x4] = __vpermilps_xmmdq_memdq_immb(var_d8, 0xc0)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_645, zmm3[0].o)
float temp0_647[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
arg1[0xc].d = temp0_647[0]
*(arg1 + 0xc4) = __vextractps_memd_xmmdq_immb(temp0_647, 1)
zmm0[0].o = _mm_permute_ps(zmm1[0].o, 0xea)
*(arg1 + 0xc8) = __vextractps_memd_xmmdq_immb(temp0_647, 2)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_645, arg3[0].o)
arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm6[0].o, *(arg1 + 0xd4), 0x20)
float temp0_653[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
*(arg1 + 0xcc) = temp0_653[0]
arg1[0xd].d = __vextractps_memd_xmmdq_immb(temp0_653, 1)
zmm0[0].o = __vmulps_xmmdq_xmmdq_memdq(zmm0[0].o, temp0_152)
*(arg1 + 0xd4) = __vextractps_memd_xmmdq_immb(temp0_653, 2)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
zmm6[0].o = arg1[0xe]
zmm4[0].o = arg1[0xf]
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_645, arg5)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_645, zmm0[0].o)
zmm7 = __vxorps_xmmdq_xmmdq_xmmdq(temp0_645, temp0_645)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm7)
zmm3[0].o = _mm_permute_ps(zmm1[0].o, 0)
float temp0_663[0x4] = _mm_permute_ps(zmm6[0].o, 0x1b)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_663)
zmm12[0].o = __vmovddup_xmmdq_memq(-0.007812501848093234)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm12[0].o)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm3[0].o = _mm_permute_ps(zmm1[0].o, 0x55)
zmm5 = _mm_permute_pd(zmm6[0].o, 1)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm5)
zmm11 = data_142d3f7d0
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm11)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xaa)
zmm3[0].o = _mm_permute_ps(zmm6[0].o, 0xb1)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
zmm10 = data_142d3f7b0
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm10)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
arg3[0].o = data_142d3f640
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm7)
float temp0_683[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(
    __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(zmm0[0].o, 0), _mm_permute_ps(zmm4[0].o, 0x1b)), 
    zmm12[0].o)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_683)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(
    __vmulps_xmmdq_xmmdq_xmmdq(
        __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(zmm0[0].o, 0x55), _mm_permute_pd(zmm4[0].o, 1)), 
        zmm11), 
    zmm3[0].o)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xaa)
float temp0_691[0x4] = _mm_permute_ps(zmm4[0].o, 0xb1)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_691)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm10)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm3[0].o)
float temp0_695[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm1[0].o)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm1[0].o)
arg3[0].o = _mm_permute_pd(zmm0[0].o, 1)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = __vmovshdup_xmmdq_xmmdq(zmm0[0].o)
arg3[0].o = zmm0[0].o f+ arg3[0]
zmm3[0].o = _mm_cmp_ss(0x322bcc77, arg3[0], 6)
zmm6[0].o = 0x3f000000
zmm5 = arg3[0].o f* 0.5f
arg3[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(arg3[0].o, arg3[0])
zmm0[0].o = arg3[0].o f* arg3[0]
zmm0[0].o = zmm0[0].o f* zmm5[0]
zmm0[0].o = 0x3f000000 f- zmm0[0]
zmm0[0].o = arg3[0].o f* zmm0[0]
zmm0[0].o = arg3[0].o f+ zmm0[0]
arg3[0].o = zmm0[0].o f* zmm0[0]
arg3[0].o = zmm5 f* arg3[0]
zmm3[0].o = __vandnps_xmmdq_xmmdq_xmmdq(zmm3[0].o, 0xffffffff)
arg3[0].o = 0x3f000000 f- arg3[0]
arg3[0].o = zmm0[0].o f* arg3[0]
zmm0[0].o = zmm0[0].o f+ arg3[0]
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
zmm1[0].o = _mm_permute_ps(zmm3[0].o, 0)
arg3 = __vandnps_ymmqq_ymmqq_memqq(zmm1, data_142fc9280)
zmm0 = _mm256_and_ps(zmm0, zmm1)
zmm9 = _mm256_or_ps(zmm0, arg3)
int64_t rdx = __vpextrq_gpr64q_xmmdq_immb(zmm9, 1)
int64_t rax_7 = zmm9[0].q
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_695)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
arg3[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
arg3[0].o = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
zmm1[0].o = zmm1[0].o f+ arg3[0]
arg3[0].o = _mm_cmp_ss(0x322bcc77, zmm1[0].d, 6)
arg3[0].o = __vandnps_xmmdq_xmmdq_xmmdq(arg3[0].o, 0xffffffff)
zmm3[0].o = zmm1[0].o f* 0.5f
zmm1[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm1[0].o, zmm1[0].d)
zmm4[0].o = zmm1[0].o f* zmm1[0].d
zmm4[0].o = zmm4[0].o f* zmm3[0].d
zmm4[0].o = 0x3f000000 f- zmm4[0].d
zmm4[0].o = zmm1[0].o f* zmm4[0].d
zmm1[0].o = zmm1[0].o f+ zmm4[0].d
zmm4[0].o = zmm1[0].o f* zmm1[0].d
zmm3[0].o = zmm3[0].o f* zmm4[0].d
zmm3[0].o = 0x3f000000 f- zmm3[0].d
zmm3[0].o = zmm1[0].o f* zmm3[0].d
zmm1[0].o = zmm1[0].o f+ zmm3[0].d
zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = _mm_permute_ps(arg3[0].o, 0)
zmm0[0].o = __vandps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = __vandnps_xmmdq_xmmdq_memdq(zmm1[0].o, data_142d3f660)
zmm0[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm9, zmm0[0].o)
arg3[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
arg3[0].o = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
zmm1[0].o = zmm1[0].o f+ arg3[0]
arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
zmm1[0].o = _mm_cmp_ss(arg3[0].o, zmm1[0].d, 2)
zmm1[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0xbf800000, 0x3f800000, zmm1[0].o)
zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
arg1[0xe] = zmm9
arg1[0xf] = zmm4[0].o
zmm0[0].o = zx.o(rax_7.d)
zmm1[0].o = zx.o(rdx.d)
uint32_t result = (rax_7 u>> 0x20).d
arg3[0].o = zx.o(result)
zmm3[0].o = *(arg1 + 0x18)
float temp0_734[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x10), zmm0[0].o, 0x20)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 0x10)
zmm1[0].o = arg1[1].d
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x20)
arg3[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0x14))
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x20)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm1[0].o, 0x10)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, *(arg1 + 0x14), 0x20)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_734, zmm1[0].o)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
arg3[0].o = __vmovsd_xmmdq_memq(arg1[1].q)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm1[0].o)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x20)
zmm3[0].o = zx.o((rdx u>> 0x20).d)
zmm3[0].o = __vpshufd_xmmdq_xmmdq_immb(zmm3[0].o, 0xc0)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm1[0].o)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm3[0].o = _mm_permute_ps(zmm1[0].o, 0xd2)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_734, zmm3[0].o)
zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xc9)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_647, zmm0[0].o)
arg1[8].d = zmm0[0]
*(arg1 + 0x84) = __vextractps_memd_xmmdq_immb(zmm0[0].o, 1)
*(arg1 + 0x88) = __vextractps_memd_xmmdq_immb(zmm0[0].o, 2)
zmm0[0].o = *(arg1 + 0x48)
zmm1[0].o = arg1[4].d
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x10)
arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(arg3[0].o, *(arg1 + 0x44), 0x20)
zmm3[0].o = _mm_permute_ps(zmm4[0].o, 0xc9)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(__vmovsd_xmmdq_memq(*(arg1 + 0x44)), zmm1[0].o, 0x20)
float temp0_765[0x4] = _mm_permute_ps(zmm4[0].o, 0xd2)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_765, zmm1[0].o)
zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm1[0].o)
arg3[0].o = __vmovsd_xmmdq_memq(arg1[4].q)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm1[0].o)
zmm4[0].o = _mm_permute_ps(zmm4[0].o, 0xff)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm1[0].o)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm0[0].o, 0x20)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
arg3[0].o = _mm_permute_ps(zmm1[0].o, 0xd2)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, arg3[0].o)
zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xc9)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_765, zmm1[0].o)
zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm1[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_653, zmm0[0].o)
*(arg1 + 0x8c) = zmm0[0]
arg1[9].d = __vextractps_memd_xmmdq_immb(zmm0[0].o, 1)
*(arg1 + 0x94) = __vextractps_memd_xmmdq_immb(zmm0[0].o, 2)
zmm0[0].o = _mm_broadcast_ss(*(arg1 + 0xec))
zmm1[0].o = *arg1
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
arg3[0].o = _mm_broadcast_ss(arg1[0xe].d)
zmm3[0].o = *(arg1 + 0xc)
zmm4[0].o = *(arg1 + 8)
zmm5 = *(arg1 + 4)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm4[0].o, 0x10)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm5, 0x20)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm1[0].o, 0x30)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm6[0].o)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm12[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xe4))
zmm6[0].o = __vmovsd_xmmdq_memq(*(arg1 + 8))
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm1[0].o, 0x20)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm5, 0x30)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, arg3[0].o)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm11)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xe8))
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm5, zmm1[0].o, 0x10)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm3[0].o, 0x20)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm4[0].o, 0x30)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm10)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
zmm0[0].o = arg1[3]
zmm1[0].o = _mm_broadcast_ss(arg1[0xf].d)
arg3[0].o = *(arg1 + 0x3c)
zmm4[0].o = *(arg1 + 0x38)
zmm5 = *(arg1 + 0x34)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm4[0].o, 0x10)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm5, 0x20)
zmm6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6[0].o, zmm0[0].o, 0x30)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm6[0].o)
zmm6[0].o = _mm_broadcast_ss(*(arg1 + 0xfc))
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm6[0].o)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm12[0].o)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm1[0].o)
zmm6[0].o = _mm_broadcast_ss(*(arg1 + 0xf4))
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(
        __vinsertps_xmmdq_xmmdq_xmmdq_immb(__vmovsd_xmmdq_memq(*(arg1 + 0x38)), zmm0[0].o, 0x20), 
        zmm5, 0x30), 
    zmm6[0].o)
zmm6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].o, zmm11)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm6[0].o)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm5, zmm0[0].o, 0x10)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x20)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x30)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xf8))
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm10)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
arg3[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
arg3[0].o = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
zmm1[0].o = zmm1[0].o f+ arg3[0]
arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
zmm1[0].o = _mm_cmp_ss(arg3[0].o, zmm1[0].d, 2)
zmm1[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0xbf800000, 0x3f800000, zmm1[0].o)
zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
arg1[0xa] = zmm3[0].o
arg1[0xb] = zmm0[0].o
_mm256_zeroupper()
return result
