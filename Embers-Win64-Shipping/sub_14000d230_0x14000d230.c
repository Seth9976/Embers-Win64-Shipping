// 函数: sub_14000d230
// 地址: 0x14000d230
// 来自: E:\Embers\Embers\Binaries\Win64\Embers-Win64-Shipping.exe

int32_t var_a8[0x4] = arg5
float var_d8 = arg3[0]
float zmm0[0x8]
zmm0[0].o = arg1[0xe]
float zmm1[0x8]
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
zmm0[0].o = _mm_broadcastss_ps(zmm0[0].o)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xe4))
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
float zmm3[0x8]
zmm3[0].o = _mm_broadcast_ss(*(arg1 + 0xec))
uint32_t zmm4[0x8]
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
zmm1[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm1[0].o = zmm1[0].o f* *(arg1 + 0xe8)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x88)
float temp0_9[0x4] = _mm_permute_ps(zmm3[0].o, 0xd8)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_9)
zmm4[0].o = __vsubps_xmmdq_xmmdq_xmmdq(temp0_9, zmm4[0].o)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x4e), zmm0[0].o, 0xc)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0x78)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm1[0].o, 0x1c)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg3[0].o, 0x60)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
float temp0_18[0x4] = _mm_broadcast_ss(1f)
float temp0_19[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(temp0_18, zmm1[0].o)
float zmm12[0x4] = arg1[6].d
int32_t temp0_20[0x4] = __vxorps_xmmdq_xmmdq_xmmdq(arg5, arg5)
float temp0_21[0x4] = __vinsertps_xmmdq_xmmdq_memd_immb(temp0_20, *(arg1 + 0x64), 0x10)
arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(temp0_20, *(arg1 + 0x68), 0x20)
float zmm10[0x4] = *(arg1 + 0x6c)
zmm0[0].o = _mm_broadcastss_ps(temp0_19)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm12, zmm0[0].o)
zmm1[0].o = _mm_permute_ps(zmm4[0].o, 0xea)
zmm1[0].o = _mm_fmadd_ps(zmm1[0].o, temp0_21, zmm0[0].o)
zmm0[0].o = _mm_permute_ps(zmm3[0].o, 0xd5)
zmm0[0].o = _mm_fmadd_ps(zmm0[0].o, arg3[0].o, zmm1[0].o)
float zmm11[0x8]
zmm11[0].o = _mm_permute_ps(zmm3[0].o, 0xea)
zmm1[0].o = _mm_permute_ps(temp0_19, 0xd5)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_21, zmm1[0].o)
zmm1[0].o = _mm_fmadd_ps(zmm1[0].o, zmm12, zmm11[0].o)
float temp0_34[0x4] = _mm_fmadd_ps(_mm_broadcastss_ps(zmm4[0].o), arg3[0].o, zmm1[0].o)
zmm11[0].o = _mm_permute_ps(zmm4[0].o, 0xd5)
zmm1[0].o = _mm_broadcastss_ps(zmm3[0].o)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_21, zmm1[0].o)
zmm1[0].o = _mm_fmadd_ps(zmm1[0].o, zmm12, zmm11[0].o)
float temp0_40[0x4] = _mm_fmadd_ps(_mm_permute_ps(temp0_19, 0xea), arg3[0].o, zmm1[0].o)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(temp0_19, zmm3[0].o, 0x9c)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm4[0].o, 0x60)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(temp0_19, zmm4[0].o, 0x8c)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x20)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm3[0].o, 0x4e)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm4[0].o, 0x14)
zmm3[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, temp0_19, 4)
zmm4[0].o = _mm_broadcastss_ps(zmm0[0].o)
float temp0_49[0x4] = _mm_permute_ps(zmm0[0].o, 0xd5)
float temp0_51[0x4] =
    _mm_fmadd_ps(__vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_49), zmm1[0].o, zmm4[0].o)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xea)
zmm0[0].o = _mm_fmadd_ps(zmm0[0].o, zmm3[0].o, temp0_51)
float var_1c8[0x4] = zmm0[0].o
zmm0[0].o = _mm_broadcastss_ps(temp0_34)
zmm4[0].o = _mm_permute_ps(temp0_34, 0xd5)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
zmm4[0].o = _mm_fmadd_ps(zmm4[0].o, zmm1[0].o, zmm0[0].o)
float temp0_59[0x4] = _mm_fmadd_ps(_mm_permute_ps(temp0_34, 0xea), zmm3[0].o, zmm4[0].o)
zmm0[0].o = _mm_broadcastss_ps(temp0_40)
zmm4[0].o = _mm_permute_ps(temp0_40, 0xd5)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
arg3[0].o = _mm_fmadd_ps(arg3[0].o, zmm1[0].o, zmm0[0].o)
zmm11[0].o = _mm_permute_ps(temp0_40, 0xea)
zmm11[0].o = _mm_fmadd_ps(zmm11[0].o, zmm3[0].o, arg3[0].o)
zmm0[0].o = arg1[0xf]
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
zmm0[0].o = _mm_broadcastss_ps(zmm0[0].o)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xf4))
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
zmm3[0].o = _mm_broadcast_ss(*(arg1 + 0xfc))
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
zmm1[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm1[0].o = zmm1[0].o f* *(arg1 + 0xf8)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x88)
float temp0_75[0x4] = _mm_permute_ps(zmm3[0].o, 0xd8)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_75)
zmm4[0].o = __vsubps_xmmdq_xmmdq_xmmdq(temp0_75, zmm4[0].o)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x4e), zmm0[0].o, 0xc)
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0x78)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm1[0].o, 0x1c)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg3[0].o, 0x60)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(temp0_18, zmm0[0].o)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(temp0_20, arg1[7].d, 0x10)
arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(temp0_20, *(arg1 + 0x74), 0x20)
float temp0_88[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm10, _mm_broadcastss_ps(zmm0[0].o))
float temp0_90[0x4] = _mm_fmadd_ps(_mm_permute_ps(zmm4[0].o, 0xea), zmm1[0].o, temp0_88)
float temp0_92[0x4] = _mm_fmadd_ps(_mm_permute_ps(zmm3[0].o, 0xd5), arg3[0].o, temp0_90)
float temp0_93[0x4] = _mm_permute_ps(zmm3[0].o, 0xea)
float temp0_94[0x4] = _mm_permute_ps(zmm0[0].o, 0xd5)
float temp0_96[0x4] = _mm_fmadd_ps(__vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_94), zmm10, temp0_93)
float temp0_98[0x4] = _mm_fmadd_ps(_mm_broadcastss_ps(zmm4[0].o), arg3[0].o, temp0_96)
arg5 = _mm_permute_ps(zmm4[0].o, 0xd5)
float temp0_100[0x4] = _mm_broadcastss_ps(zmm3[0].o)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_100)
zmm1[0].o = _mm_fmadd_ps(zmm1[0].o, zmm10, arg5)
float temp0_104[0x4] = _mm_fmadd_ps(_mm_permute_ps(zmm0[0].o, 0xea), arg3[0].o, zmm1[0].o)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm3[0].o, 0x9c)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm4[0].o, 0x60)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x8c)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x20)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm3[0].o, 0x4e)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm4[0].o, 0x14)
zmm0[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm0[0].o, 4)
zmm3[0].o = _mm_broadcastss_ps(temp0_92)
zmm4[0].o = _mm_permute_ps(temp0_92, 0xd5)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
zmm4[0].o = _mm_fmadd_ps(zmm4[0].o, zmm1[0].o, zmm3[0].o)
zmm3[0].o = _mm_permute_ps(temp0_92, 0xea)
zmm3[0].o = _mm_fmadd_ps(zmm3[0].o, zmm0[0].o, zmm4[0].o)
float var_1a8[0x4] = zmm3[0].o
zmm3[0].o = _mm_broadcastss_ps(temp0_98)
zmm4[0].o = _mm_permute_ps(temp0_98, 0xd5)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
zmm4[0].o = _mm_fmadd_ps(zmm4[0].o, zmm1[0].o, zmm3[0].o)
float temp0_123[0x4] = _mm_fmadd_ps(_mm_permute_ps(temp0_98, 0xea), zmm0[0].o, zmm4[0].o)
zmm3[0].o = _mm_broadcastss_ps(temp0_104)
zmm4[0].o = _mm_permute_ps(temp0_104, 0xd5)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
arg3[0].o = _mm_fmadd_ps(arg3[0].o, zmm1[0].o, zmm3[0].o)
float temp0_129[0x4] = _mm_fmadd_ps(_mm_permute_ps(temp0_104, 0xea), zmm0[0].o, arg3[0].o)
zmm0[0].o = __vmovsd_xmmdq_memq(arg1[8].q)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, *(arg1 + 0x88), 0x20)
zmm1[0].o = __vmovsd_xmmdq_memq(arg1[0xc].q)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, *(arg1 + 0xc8), 0x20)
zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
float temp0_135[0x4] = _mm_broadcast_ss(-0f)
arg3[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm0[0].o = __vxorpd_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_135)
zmm3[0].o = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
zmm4[0].o = _mm_permute_ps(zmm0[0].o, 0x80)
float temp0_141[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(temp0_59, 0xc1), zmm4[0].o)
float temp0_142[0x4] = _mm_permute_ps(zmm1[0].o, 0xd5)
float temp0_144[0x4] = _mm_fmadd_ps(_mm_permute_ps(zmm11[0].o, 0xc1), temp0_142, temp0_141)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(__vmovshdup_xmmdq_xmmdq(zmm11[0].o), temp0_59, 0x68), 
    zmm4[0].o)
float temp0_149[0x4] = _mm_fmadd_ps(_mm_permute_ps(zmm11[0].o, 0xda), temp0_142, zmm4[0].o)
zmm4[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_135)
float zmm6[0x4] = __vxorps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_135)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x9c)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x20)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm6, 0x10)
zmm3[0].o = zmm3[0].q | zmm1[0].q << 0x40
arg5 = _mm_fmadd_ps(__vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_149), temp0_144, zmm0[0].o)
zmm0[0].o = _mm_permute_ps(zmm1[0].o, 0x4a)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x20)
zmm3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm6, zmm1[0].o, 0x40)
float temp0_160[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_59, zmm11[0].o, 0x30)
float temp0_162[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(
    __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm11[0].o, temp0_160, 0x80), zmm3[0].o)
float temp0_164[0x4] =
    _mm_fmadd_ps(__vpermilps_xmmdq_memdq_immb(var_1c8, 0xc0), zmm0[0].o, temp0_162)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm4[0].o, 0x10)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm4[0].o, 0x20)
zmm4[0].o = _mm_permute_ps(zmm11[0].o, 0x46)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, temp0_59, 0x68)
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm3[0].o)
float var_168[0x4] = zmm11[0].o
zmm4[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm11[0].o, temp0_59, 0xc)
zmm4[0].o = _mm_permute_ps(zmm4[0].o, 0x78)
zmm3[0].o = _mm_fmadd_ps(zmm3[0].o, zmm0[0].o, zmm4[0].o)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm6, zmm1[0].o, 0)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0xc8)
float temp0_176[0x4] =
    _mm_fmadd_ps(__vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm3[0].o), temp0_164, arg3[0].o)
zmm0[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0x8c))
zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, *(arg1 + 0x94), 0x20)
zmm1[0].o = *(arg1 + 0xd4)
arg3[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0xcc))
float var_198[0x4] = zmm1[0].o
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x20)
arg3[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
float zmm9[0x4] = _mm_permute_pd(arg3[0].o, 1)
zmm0[0].o = __vxorpd_xmmdq_xmmdq_xmmdq(zmm9, temp0_135)
zmm4[0].o = _mm_permute_ps(zmm0[0].o, 0x80)
float temp0_186[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(temp0_123, 0xc1), zmm4[0].o)
float temp0_187[0x4] = _mm_permute_ps(arg3[0].o, 0xd5)
float temp0_189[0x4] = _mm_fmadd_ps(_mm_permute_ps(temp0_129, 0xc1), temp0_187, temp0_186)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(__vmovshdup_xmmdq_xmmdq(temp0_129), temp0_123, 0x68), 
    zmm4[0].o)
float temp0_194[0x4] = _mm_fmadd_ps(_mm_permute_ps(temp0_129, 0xda), temp0_187, zmm4[0].o)
zmm4[0].o = __vmovshdup_xmmdq_xmmdq(arg3[0].o)
zmm11[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_135)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm11[0].o, 0x10)
zmm3[0].o = zmm3[0].q | arg3[0].q << 0x40
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_194)
zmm4[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_135)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x9c)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x20)
zmm3[0].o = _mm_fmadd_ps(zmm3[0].o, temp0_189, zmm0[0].o)
zmm0[0].o = _mm_permute_ps(arg3[0].o, 0x4a)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x20)
float temp0_206[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_129, 
    __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_123, temp0_129, 0x30), 0x80)
float temp0_207[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm11[0].o, arg3[0].o, 0x40)
float temp0_208[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_206, temp0_207)
zmm1[0].o = var_1a8
zmm1[0].o = _mm_broadcastss_ps(zmm1[0].o)
zmm1[0].o = _mm_fmadd_ps(zmm1[0].o, zmm0[0].o, temp0_208)
float temp0_213[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(_mm_permute_ps(temp0_129, 0x46), temp0_123, 0x68), temp0_207)
float temp0_215[0x4] =
    _mm_permute_ps(__vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_129, temp0_123, 0xc), 0x78)
float temp0_216[0x4] = _mm_fmadd_ps(temp0_213, zmm0[0].o, temp0_215)
zmm0[0].o = *(arg1 + 0x78)
float temp0_217[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg5)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, *(arg1 + 0x78), 0x20)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_176)
zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm9, zmm4[0].o, 0x10), zmm4[0].o, 0x20)
arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(
    __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm11[0].o, arg3[0].o, 0), arg3[0].o, 0xc8)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_216)
zmm6 = *(arg1 + 0x7c)
zmm3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm6, zmm3[0].o)
arg3[0].o = _mm_fmadd_ps(arg3[0].o, zmm1[0].o, zmm4[0].o)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6, zmm6, 0x20)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(temp0_217, zmm0[0].o, 5)
arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm0[0].o, 0xd8)
zmm4[0].o = _mm_permute_pd(temp0_217, 1)
zmm4[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 1)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm1[0].o, 5)
zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0xd8)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
zmm0[0].o = _mm_permute_pd(zmm3[0].o, 1)
zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 1)
zmm0 = *arg4
int32_t temp0_238 = _mm256_movemask_ps(zmm0)
int32_t temp0_239 = __vextractps_gpr32_xmmdq_immb(var_1c8, 1)
int32_t temp0_240 = __vextractps_gpr32_xmmdq_immb(var_1c8, 2)
int32_t temp0_241 = __vextractps_gpr32_xmmdq_immb(temp0_59, 2)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm1[0].o)
float zmm15[0x4] = __vmovshdup_xmmdq_xmmdq(temp0_59)
int32_t temp0_244 = __vextractps_gpr32_xmmdq_immb(arg3[0].o, 0)
int32_t temp0_245 = __vextractps_gpr32_xmmdq_immb(arg3[0].o, 1)
int32_t temp0_246 = __vextractps_gpr32_xmmdq_immb(arg3[0].o, 2)
int32_t temp0_247 = __vextractps_gpr32_xmmdq_immb(zmm1[0].o, 0)
int32_t temp0_248 = __vextractps_gpr32_xmmdq_immb(zmm1[0].o, 1)
int32_t temp0_249 = __vextractps_gpr32_xmmdq_immb(zmm1[0].o, 2)
zmm11[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_217, zmm3[0].o)
zmm1[0].o = __vmovshdup_xmmdq_xmmdq(zmm11[0].o)
float var_1b8[0x4] = zmm1[0].o
arg3 = _mm256_blend_ps(_mm256_broadcast_ss(1.17549435e-38f), zmm11, 7)
zmm1 = _mm256_broadcast_ss(nanf)
zmm3 = _mm256_and_ps(arg3, zmm1)
zmm10 = _mm_permute_pd(zmm11[0].o, 1)
float var_128[0x4] = zmm15
float var_108[0x4] = zmm6
float var_118[0x4] = zmm10
float zmm5[0x4]
float zmm7[0x4]
float zmm13[0x4]
float zmm14[0x4]

if (temp0_238 != 0xff)
    arg3 = _mm256_broadcast_ss(9.99999994e-09f)
    zmm4 = _mm256_cmp_ps(zmm3, arg3, 2)
    zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
    zmm3 = _mm256_cmpeq_epi32(zmm0, zmm3)
    zmm4 = _mm256_or_ps(zmm4, zmm3)
    zmm5 = _mm256_extractf128_ps(zmm4[0].o, 1)
    zmm4[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm5)
    zmm4[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm0[0].o)
    arg5 = zx.o(temp0_244)
    zmm13 = zx.o(temp0_245)
    zmm9 = zx.o(temp0_246)
    
    if (__vpmovmskb_gpr32d_xmmdq(zmm4[0].o) != 0xff)
    label_14000dc6e:
        float temp0_384[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm10, zmm9, 0x2a)
        zmm15 = zx.o(temp0_247)
        zmm5 = zx.o(temp0_248)
        float temp0_385[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm15, zmm5, 0x1c)
        zmm7 = zx.o(temp0_249)
        zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm11[0].o, zmm10, 0x10)
        zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm15, 0x20)
        zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm7, 0x30)
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm13, 1f, 0x36)
        arg3[0].o = var_1b8
        float temp0_390[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm5, 0x2a)
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg5, zmm9, 0x1c)
        float temp0_393[0x4] =
            _mm_fmsub_ps(__vmulps_xmmdq_xmmdq_xmmdq(temp0_390, zmm4[0].o), zmm0[0].o, zmm1[0].o)
        zmm0[0].o = _mm_broadcastss_ps(temp0_393)
        int128_t var_138_2 = zmm0[0].o
        zmm4[0].o = _mm_permute_ps(temp0_393, 0x55)
        float temp0_396[0x4] = _mm_permute_ps(temp0_393, 0xaa)
        zmm3[0].o = _mm_permute_ps(temp0_393, 0xff)
        zmm1[0].o = 0x3f800000
        zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(0x3f800000, zmm7, 0)
        float temp0_399[0x4] = __vunpcklps_xmmdq_xmmdq_xmmdq(zmm15, zmm5)
        zmm6 = __vxorps_xmmdq_xmmdq_xmmdq(temp0_393, temp0_393)
        float temp0_401[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm6[0].q | temp0_399[0].q << 0x40, zmm6)
        zmm0[0].o = _mm_fmsub_ps(zmm0[0].o, temp0_385, temp0_401)
        float var_148_2 = zmm13[0]
        float temp0_404[0x4] =
            __vshufps_xmmdq_xmmdq_xmmdq_immb(_mm_broadcastss_ps(zmm13), zmm11[0].o, 4)
        float temp0_405[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, arg5, 0)
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm9, zmm11[0].o, 0xaa)
        float temp0_408[0x4] =
            _mm_fmsub_ps(__vmulps_xmmdq_xmmdq_xmmdq(temp0_405, arg3[0].o), temp0_384, temp0_404)
        zmm10 = zmm4[0].o
        zmm4[0].o = var_138_2
        arg3[0].o = _mm_permute_ps(zmm0[0].o, 0xd8)
        arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_408, arg3[0].o)
        zmm6 = _mm_permute_pd(arg3[0].o, 1)
        arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm6)
        float temp0_413[0x4] = _mm_permute_ps(arg3[0].o, 0x39)
        arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_413)
        float temp0_417[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(
            _mm_fmadd_ps(__vmulps_xmmdq_xmmdq_xmmdq(zmm10, temp0_396), zmm4[0].o, zmm3[0].o), 
            arg3[0].o)
        arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
        temp0_417 f- arg3[0]
        
        if (temp0_417 f!= arg3[0] || not(is_ordered.d(temp0_417, arg3[0])))
            zmm13 = zmm3[0].o
            zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm7, 1f, 0x36)
            arg3[0].o = data_142d4cc30
            arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm7, 0x10)
            float temp0_421[0x4] = _mm_permute_ps(temp0_408, 0x66)
            arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_421)
            float temp0_423[0x4] = _mm_permute_ps(temp0_408, 0x33)
            arg3[0].o = _mm_fmsub_ps(arg3[0].o, zmm1[0].o, temp0_423)
            float temp0_425[0x4] = _mm_fmsub_ps(zmm10, temp0_385, arg3[0].o)
            arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm15, 0x1d)
            zmm3[0].o = __vmovddup_xmmdq_xmmq(temp0_408[0].q)
            arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
            zmm3[0].o = _mm_permute_pd(temp0_408, 3)
            arg3[0].o = _mm_fmadd_ps(arg3[0].o, temp0_385, zmm3[0].o)
            zmm4[0].o = _mm_fmsub_ps(zmm4[0].o, zmm1[0].o, arg3[0].o)
            zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm11[0].o, arg5, 0x20)
            zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, var_148_2, 0x30)
            arg3[0].o = __vmovsldup_xmmdq_xmmdq(zmm11[0].o)
            arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, arg5, 0x30)
            zmm3[0].o = __vmovddup_xmmdq_xmmq(zmm0[0].q)
            arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
            zmm3[0].o = _mm_broadcastss_ps(zmm0[0].o)
            arg3[0].o = _mm_fmsub_ps(arg3[0].o, zmm1[0].o, zmm3[0].o)
            float temp0_440[0x4] = _mm_fmsub_ps(temp0_396, temp0_384, arg3[0].o)
            zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
            arg3[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm9, 1)
            zmm3[0].o = __vblendps_xmmdq_xmmdq_memdq_immb(zmm3[0].o, var_118, 1)
            arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, arg3[0].o, 0x11)
            zmm3[0].o = _mm_permute_ps(zmm0[0].o, 0x66)
            arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
            zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xcc)
            arg3[0].o = _mm_fmadd_ps(arg3[0].o, temp0_384, zmm0[0].o)
            float temp0_449[0x4] = _mm_fmsub_ps(zmm13, zmm1[0].o, arg3[0].o)
            zmm0[0].o = data_142fc92f0
            zmm0[0].o = __vdivps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_417)
            arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_449, zmm0[0].o)
            zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_425, zmm0[0].o)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_440, zmm0[0].o)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm0[0].o)
            zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 0x77)
            zmm1[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x77)
            arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x22)
        else
            arg3[0].o = data_142d4cc20
            zmm0[0].o = data_142d4cc30
        
        zmm14 = var_168
        zmm13 = temp0_123
        zmm15 = temp0_135
        arg5 = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
        zmm9 = _mm_permute_pd(zmm1[0].o, 1)
        zmm10 = _mm_permute_ps(zmm1[0].o, 0xe7)
        zmm11[0].o = __vmovshdup_xmmdq_xmmdq(arg3[0].o)
        zmm7 = _mm_permute_pd(arg3[0].o, 1)
        zmm3[0].o = _mm_permute_ps(arg3[0].o, 0xe7)
        zmm5 = __vmovshdup_xmmdq_xmmdq(zmm0[0].o)
        zmm6 = _mm_permute_pd(zmm0[0].o, 1)
        zmm4[0].o = _mm_permute_ps(zmm0[0].o, 0xe7)
    else
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg5, zmm13, 0x10)
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm9, 0x20)
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, 0x800000, 0x30)
        float temp0_362[0x4] = _mm_broadcastss_ps(0x800000)
        zmm4 = _mm256_cmp_ps(_mm256_and_ps(_mm256_insertf128_ps(zmm4, temp0_362, 1), zmm1), arg3, 2)
        zmm3 = _mm256_or_ps(zmm4, zmm3)
        zmm4[0].o = _mm256_extractf128_ps(zmm3[0].o, 1)
        zmm3[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm4[0].o)
        zmm3[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
        
        if (__vpmovmskb_gpr32d_xmmdq(zmm3[0].o) != 0xff)
            goto label_14000dc6e
        
        zmm3[0].o = zx.o(0)
        zmm0 = _mm256_cmpeq_epi32(zmm0, zmm3)
        zmm3[0].o = zx.o(temp0_247)
        zmm4[0].o = zx.o(temp0_248)
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm4[0].o, 0x10)
        zmm4[0].o = zx.o(temp0_249)
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm4[0].o, 0x20)
        zmm4[0].o = 0x800000
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, 0x800000, 0x30)
        zmm4[0].o = _mm_broadcastss_ps(0x800000)
        zmm3 = _mm256_insertf128_ps(zmm3, zmm4[0].o, 1)
        zmm1 = _mm256_cmp_ps(_mm256_and_ps(zmm3, zmm1), arg3, 2)
        zmm0 = _mm256_or_ps(zmm1, zmm0)
        zmm1[0].o = _mm256_extractf128_ps(zmm0[0].o, 1)
        zmm0[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
        zmm0[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
        
        if (__vpmovmskb_gpr32d_xmmdq(zmm0[0].o) != 0xff)
            goto label_14000dc6e
        
        zmm6 = 0x3f800000
        zmm4[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm4[0].o)
        zmm5 = __vxorps_xmmdq_xmmdq_xmmdq(temp0_362, temp0_362)
        zmm0[0].o = zx.o(0)
        zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
        zmm7 = __vxorpd_xmmdq_xmmdq_xmmdq(temp0_217, temp0_217)
        zmm11[0].o = 0x3f800000
        arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
        zmm10 = __vxorps_xmmdq_xmmdq_xmmdq(zmm10, zmm10)
        zmm9 = __vxorps_xmmdq_xmmdq_xmmdq(zmm9, zmm9)
        arg5 = __vxorps_xmmdq_xmmdq_xmmdq(arg5, arg5)
        zmm1[0].o = 0x3f800000
        zmm14 = var_168
        zmm13 = temp0_123
        zmm15 = temp0_135
    
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm5, 0x10)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm6, 0x20)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x30)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm11[0].o, 0x10)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm7, 0x20)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x30)
    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg5, 0x10)
    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm9, 0x20)
    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm10, 0x30)
    zmm3[0].o = _mm_broadcast_ss(*arg2)
    zmm4[0].o = _mm_broadcast_ss(arg2[1])
    arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
    arg3[0].o = _mm_fmadd_ps(arg3[0].o, zmm1[0].o, zmm3[0].o)
    zmm3[0].o = _mm_broadcast_ss(arg2[2])
    zmm3[0].o = _mm_fmadd_ps(zmm3[0].o, zmm0[0].o, arg3[0].o)
    zmm0[0].o = _mm_broadcast_ss(*(arg1 + 0x78))
    float temp0_555[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
    zmm0[0].o = __vxorps_xmmdq_xmmdq_memdq(zmm15, var_108)
    zmm0[0].o = _mm_broadcastss_ps(zmm0[0].o)
    arg5 = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
    arg3[0].o = __vmovsd_xmmdq_memq(arg1[8].q)
    zmm4[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(arg3[0].o, *(arg1 + 0x88), 0x20)
    arg3[0].o = __vmovsd_xmmdq_memq(arg1[0xc].q)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(arg3[0].o, *(arg1 + 0xc8), 0x20)
    zmm4[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
    float temp0_564[0x4] = _mm_permute_ps(zmm4[0].o, 0xc9)
    zmm4[0].o = _mm_permute_ps(zmm4[0].o, 0xd2)
    zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(zmm3[0].o, 0xc9), zmm4[0].o)
    float temp0_568[0x4] = _mm_permute_ps(zmm3[0].o, 0xd2)
    zmm4[0].o = _mm_fmsub_ps(zmm4[0].o, temp0_564, temp0_568)
    zmm5 = __vmovsd_xmmdq_memq(*(arg1 + 0x8c))
    zmm0[0].o = var_1c8
    float temp0_572[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(
        __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zx.o(temp0_239), 0x10), zx.o(temp0_240), 0x20)
    zmm0[0].o = temp0_59
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, var_128[0], 0x10)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zx.o(temp0_241), 0x20)
    float temp0_575[0x4] = _mm_broadcastss_ps(zmm4[0].o)
    zmm1[0].o = _mm_permute_ps(zmm4[0].o, 0xd5)
    zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
    zmm0[0].o = _mm_fmadd_ps(zmm0[0].o, temp0_572, temp0_575)
    zmm6 = _mm_fmadd_ps(_mm_permute_ps(zmm4[0].o, 0xea), zmm14, zmm0[0].o)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm5, *(arg1 + 0x94), 0x20)
    zmm1[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0xcc))
    zmm4[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, var_198[0], 0x20)
    zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
    zmm4[0].o = _mm_permute_ps(zmm0[0].o, 0xc9)
    float temp0_586[0x4] = _mm_broadcast_ss(-0f)
    zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_586)
    float temp0_588[0x4] = _mm_permute_ps(zmm3[0].o, 0xd2)
    zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xd2)
    zmm3[0].o = _mm_permute_ps(zmm3[0].o, 0xc9)
    zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
    zmm7 = _mm_broadcast_ss(var_d8)
    zmm12 = _mm_fmadd_ps(temp0_555, zmm7, arg3[0].o)
    arg1[0xc].d = zmm12[0]
    zmm0[0].o = _mm_fmsub_ps(zmm0[0].o, zmm4[0].o, temp0_588)
    *(arg1 + 0xc4) = __vextractps_memd_xmmdq_immb(zmm12, 1)
    arg3[0].o = _mm_broadcastss_ps(zmm0[0].o)
    *(arg1 + 0xc8) = __vextractps_memd_xmmdq_immb(zmm12, 2)
    zmm3[0].o = _mm_permute_ps(zmm0[0].o, 0xd5)
    zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm13, zmm3[0].o)
    zmm13 = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, *(arg1 + 0xd4), 0x20)
    zmm3[0].o = __vfmadd231ps_xmmdq_xmmdq_memdq(zmm3[0].o, arg3[0].o, var_1a8)
else
    zmm0 = _mm256_broadcast_ss(9.99999994e-09f)
    arg3 = _mm256_cmp_ps(zmm3, zmm0, 2)
    char temp0_259 = _mm256_movemask_ps(arg3)
    zmm14 = zx.o(temp0_244)
    zmm4[0].o = zx.o(temp0_245)
    zmm13 = zx.o(temp0_246)
    
    if (temp0_259 != 0xff)
    label_14000d979:
        arg5 = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm10, zmm13, 0x2a)
        zmm7 = zx.o(temp0_247)
        zmm0[0].o = zx.o(temp0_248)
        float temp0_277[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm7, zmm0[0].o, 0x1c)
        zmm12 = zx.o(temp0_249)
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm11[0].o, zmm10, 0x10)
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm7, 0x20)
        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm12, 0x30)
        arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm4[0].o, 1f, 0x36)
        zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(var_1b8, zmm0[0].o, 0x2a)
        zmm15 = zmm4[0].o
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm14, zmm13, 0x1c)
        zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm4[0].o)
        zmm3[0].o = _mm_fmsub_ps(zmm3[0].o, zmm1[0].o, arg3[0].o)
        float temp0_286[0x4] = _mm_broadcastss_ps(zmm3[0].o)
        arg3[0].o = _mm_permute_ps(zmm3[0].o, 0x55)
        zmm4[0].o = zmm13
        float temp0_288[0x4] = _mm_permute_ps(zmm3[0].o, 0xaa)
        zmm3[0].o = _mm_permute_ps(zmm3[0].o, 0xff)
        zmm1[0].o = 0x3f800000
        float temp0_290[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(0x3f800000, zmm12, 0)
        float var_158_1 = zmm7[0]
        zmm0[0].o = __vunpcklps_xmmdq_xmmdq_xmmdq(zmm7, zmm0[0].o)
        zmm7 = __vxorps_xmmdq_xmmdq_xmmdq(zmm7, zmm7)
        zmm0[0].o = zmm7[0].q | zmm0[0].q << 0x40
        zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm7)
        float temp0_294[0x4] = _mm_fmsub_ps(temp0_290, temp0_277, zmm0[0].o)
        float var_138_1 = zmm15[0]
        zmm0[0].o = _mm_broadcastss_ps(zmm15)
        zmm15 = zmm4[0].o
        zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm11[0].o, 4)
        float temp0_297[0x4] = __vshufps_xmmdq_xmmdq_xmmdq_immb(var_1b8, zmm14, 0)
        zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm11[0].o, 0xaa)
        int32_t var_1b8_1[0x4] = arg5
        float temp0_300[0x4] =
            _mm_fmsub_ps(__vmulps_xmmdq_xmmdq_xmmdq(temp0_297, zmm4[0].o), arg5, zmm0[0].o)
        zmm0[0].o = _mm_permute_ps(temp0_294, 0xd8)
        zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_300, zmm0[0].o)
        zmm4[0].o = _mm_permute_pd(zmm0[0].o, 1)
        zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
        zmm4[0].o = _mm_permute_ps(zmm0[0].o, 0x39)
        zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
        zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, temp0_288)
        zmm4[0].o = _mm_fmadd_ps(zmm4[0].o, temp0_286, zmm3[0].o)
        float temp0_309[0x4] = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm0[0].o)
        zmm4[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm4[0].o)
        temp0_309 f- zmm4[0]
        
        if (temp0_309 f!= zmm4[0] || not(is_ordered.d(temp0_309, zmm4[0])))
            arg5 = __vinsertps_xmmdq_xmmdq_memd_immb(zmm12, 1f, 0x36)
            zmm4[0].o = data_142d4cc30
            zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm12, 0x10)
            zmm1[0].o = _mm_permute_ps(temp0_300, 0x66)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm1[0].o)
            zmm4[0].o = _mm_permute_ps(temp0_300, 0x33)
            zmm1[0].o = _mm_fmsub_ps(zmm1[0].o, arg5, zmm4[0].o)
            zmm0[0].o = temp0_277
            arg3[0].o = _mm_fmsub_ps(arg3[0].o, zmm0[0].o, zmm1[0].o)
            zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, var_158_1, 0x1d)
            zmm4[0].o = __vmovddup_xmmdq_xmmq(temp0_300[0].q)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm4[0].o)
            zmm4[0].o = _mm_permute_pd(temp0_300, 3)
            zmm1[0].o = _mm_fmadd_ps(zmm1[0].o, zmm0[0].o, zmm4[0].o)
            float temp0_323[0x4] = _mm_fmsub_ps(temp0_286, arg5, zmm1[0].o)
            zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm11[0].o, zmm14, 0x20)
            zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, var_138_1, 0x30)
            zmm4[0].o = __vmovsldup_xmmdq_xmmdq(zmm11[0].o)
            zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, zmm14, 0x30)
            zmm6 = __vmovddup_xmmdq_xmmq(temp0_294[0].q)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm6)
            float temp0_330[0x4] = _mm_broadcastss_ps(temp0_294)
            zmm4[0].o = _mm_fmsub_ps(zmm4[0].o, zmm1[0].o, temp0_330)
            zmm7 = var_1b8_1
            float temp0_332[0x4] = _mm_fmsub_ps(temp0_288, zmm7, zmm4[0].o)
            zmm0[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
            zmm4[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm15, 1)
            zmm4[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(
                __vblendps_xmmdq_xmmdq_memdq_immb(zmm0[0].o, var_118, 1), zmm4[0].o, 0x11)
            float temp0_337[0x4] = _mm_permute_ps(temp0_294, 0x66)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, temp0_337)
            float temp0_339[0x4] = _mm_permute_ps(temp0_294, 0xcc)
            zmm4[0].o = _mm_fmadd_ps(zmm4[0].o, zmm7, temp0_339)
            zmm3[0].o = _mm_fmsub_ps(zmm3[0].o, zmm1[0].o, zmm4[0].o)
            zmm1[0].o = data_142fc92f0
            zmm0[0].o = __vdivps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_309)
            zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
            arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_332, zmm0[0].o)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_323, zmm0[0].o)
            zmm0[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 0x77)
            zmm1[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, arg3[0].o, 0x77)
            arg3[0].o = __vshufps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, arg3[0].o, 0x22)
        else
            arg3[0].o = data_142d4cc20
            zmm0[0].o = data_142d4cc30
        
        zmm14 = var_1a8
        zmm13 = var_198
        zmm15 = var_128
        arg5 = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
        zmm9 = _mm_permute_pd(zmm1[0].o, 1)
        zmm10 = _mm_permute_ps(zmm1[0].o, 0xe7)
        zmm11[0].o = __vmovshdup_xmmdq_xmmdq(arg3[0].o)
        zmm7 = _mm_permute_pd(arg3[0].o, 1)
        zmm3[0].o = _mm_permute_ps(arg3[0].o, 0xe7)
        zmm5 = __vmovshdup_xmmdq_xmmdq(zmm0[0].o)
        zmm6 = _mm_permute_pd(zmm0[0].o, 1)
        zmm4[0].o = _mm_permute_ps(zmm0[0].o, 0xe7)
    else
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm14, zmm4[0].o, 0x10)
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm13, 0x20)
        zmm3[0].o = 0x800000
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, 0x800000, 0x30)
        zmm3[0].o = _mm_broadcastss_ps(0x800000)
        arg3 = _mm256_cmp_ps(_mm256_and_ps(_mm256_insertf128_ps(arg3, zmm3[0].o, 1), zmm1), zmm0, 2)
        
        if (_mm256_movemask_ps(arg3) != 0xff)
            goto label_14000d979
        
        arg3[0].o = zx.o(temp0_247)
        zmm3[0].o = zx.o(temp0_248)
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x10)
        zmm3[0].o = zx.o(temp0_249)
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x20)
        zmm3[0].o = 0x800000
        arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, 0x800000, 0x30)
        zmm3[0].o = _mm_broadcastss_ps(0x800000)
        arg3 = _mm256_insertf128_ps(arg3, zmm3[0].o, 1)
        zmm1 = _mm256_and_ps(arg3, zmm1)
        zmm0 = _mm256_cmp_ps(zmm1, zmm0, 2)
        
        if (_mm256_movemask_ps(zmm0) != 0xff)
            goto label_14000d979
        
        zmm6 = 0x3f800000
        zmm4[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm4[0].o)
        zmm5 = __vxorps_xmmdq_xmmdq_xmmdq(var_1c8, var_1c8)
        zmm0[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
        zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
        zmm7 = __vxorpd_xmmdq_xmmdq_xmmdq(temp0_217, temp0_217)
        zmm11[0].o = 0x3f800000
        arg3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
        zmm10 = __vxorps_xmmdq_xmmdq_xmmdq(zmm10, zmm10)
        zmm9 = __vxorpd_xmmdq_xmmdq_xmmdq(zmm9, zmm9)
        arg5 = __vxorps_xmmdq_xmmdq_xmmdq(arg5, arg5)
        zmm1[0].o = 0x3f800000
        zmm14 = var_1a8
        zmm13 = var_198
    
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm5, 0x10)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm6, 0x20)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm4[0].o, 0x30)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm11[0].o, 0x10)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm7, 0x20)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm3[0].o, 0x30)
    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg5, 0x10)
    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm9, 0x20)
    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm10, 0x30)
    zmm3[0].o = _mm_broadcast_ss(*arg2)
    zmm4[0].o = _mm_broadcast_ss(arg2[1])
    arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm4[0].o)
    arg3[0].o = _mm_fmadd_ps(arg3[0].o, zmm1[0].o, zmm3[0].o)
    zmm3[0].o = _mm_broadcast_ss(arg2[2])
    zmm3[0].o = _mm_fmadd_ps(zmm3[0].o, zmm0[0].o, arg3[0].o)
    zmm0[0].o = _mm_broadcast_ss(*(arg1 + 0x78))
    float temp0_483[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
    zmm0[0].o = var_108
    zmm0[0].o = __vxorps_xmmdq_xmmdq_memdq(zmm0[0].o, temp0_135)
    zmm0[0].o = _mm_broadcastss_ps(zmm0[0].o)
    arg5 = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
    arg3[0].o = __vmovsd_xmmdq_memq(arg1[8].q)
    zmm4[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(arg3[0].o, *(arg1 + 0x88), 0x20)
    arg3[0].o = __vmovsd_xmmdq_memq(arg1[0xc].q)
    arg3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(arg3[0].o, *(arg1 + 0xc8), 0x20)
    zmm4[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg3[0].o)
    float temp0_492[0x4] = _mm_permute_ps(zmm4[0].o, 0xc9)
    zmm4[0].o = _mm_permute_ps(zmm4[0].o, 0xd2)
    zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(_mm_permute_ps(zmm3[0].o, 0xc9), zmm4[0].o)
    float temp0_496[0x4] = _mm_permute_ps(zmm3[0].o, 0xd2)
    zmm4[0].o = _mm_fmsub_ps(zmm4[0].o, temp0_492, temp0_496)
    zmm5 = __vmovsd_xmmdq_memq(*(arg1 + 0x8c))
    zmm0[0].o = var_1c8
    float temp0_500[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(
        __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zx.o(temp0_239), 0x10), zx.o(temp0_240), 0x20)
    zmm0[0].o = temp0_59
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm15, 0x10)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zx.o(temp0_241), 0x20)
    float temp0_503[0x4] = _mm_broadcastss_ps(zmm4[0].o)
    zmm1[0].o = _mm_permute_ps(zmm4[0].o, 0xd5)
    zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
    zmm0[0].o = _mm_fmadd_ps(zmm0[0].o, temp0_500, temp0_503)
    zmm6 = __vfmadd132ps_xmmdq_xmmdq_memdq(_mm_permute_ps(zmm4[0].o, 0xea), zmm0[0].o, var_168)
    zmm0[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm5, *(arg1 + 0x94), 0x20)
    zmm1[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0xcc))
    zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm13, 0x20)
    zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
    zmm4[0].o = _mm_permute_ps(zmm0[0].o, 0xc9)
    float temp0_514[0x4] = _mm_broadcast_ss(-0f)
    zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_514)
    float temp0_516[0x4] = _mm_permute_ps(zmm3[0].o, 0xd2)
    zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xd2)
    zmm3[0].o = _mm_permute_ps(zmm3[0].o, 0xc9)
    zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm0[0].o)
    zmm7 = _mm_broadcast_ss(var_d8)
    zmm12 = _mm_fmadd_ps(temp0_483, zmm7, arg3[0].o)
    arg1[0xc].d = zmm12[0]
    zmm0[0].o = _mm_fmsub_ps(zmm0[0].o, zmm4[0].o, temp0_516)
    *(arg1 + 0xc4) = __vextractps_memd_xmmdq_immb(zmm12, 1)
    arg3[0].o = _mm_broadcastss_ps(zmm0[0].o)
    *(arg1 + 0xc8) = __vextractps_memd_xmmdq_immb(zmm12, 2)
    zmm3[0].o = _mm_permute_ps(zmm0[0].o, 0xd5)
    zmm3[0].o = __vmulps_xmmdq_xmmdq_memdq(zmm3[0].o, temp0_123)
    zmm13 = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, *(arg1 + 0xd4), 0x20)
    zmm3[0].o = _mm_fmadd_ps(zmm3[0].o, zmm14, arg3[0].o)
float temp0_602[0x4] = _mm_fmadd_ps(zmm13, zmm7, arg5)
*(arg1 + 0xcc) = temp0_602[0]
zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xea)
arg1[0xd].d = __vextractps_memd_xmmdq_immb(temp0_602, 1)
zmm0[0].o = __vfmadd132ps_xmmdq_xmmdq_memdq(zmm0[0].o, zmm3[0].o, temp0_129)
*(arg1 + 0xd4) = __vextractps_memd_xmmdq_immb(temp0_602, 2)
zmm3[0].o = arg1[0xe]
zmm11[0].o = arg1[0xf]
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm7, zmm6)
float temp0_608[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm7, zmm0[0].o)
int32_t temp0_609[0x4] = __vxorps_xmmdq_xmmdq_xmmdq(arg5, arg5)
zmm0[0].o = _mm_broadcastss_ps(zmm1[0].o)
arg3[0].o = _mm_permute_ps(zmm3[0].o, 0x1b)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = __vpbroadcastq_xmmdq_memq(-0x407fffffc0800000)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
zmm4[0].o = arg3[0].o
int128_t var_1c8_1 = arg3[0].o
zmm0[0].o = _mm_fmadd_ps(zmm0[0].o, zmm3[0].o, temp0_609)
arg3[0].o = _mm_permute_ps(zmm1[0].o, 0x55)
zmm6 = _mm_permute_pd(zmm3[0].o, 1)
float temp0_618[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm6)
arg3[0].o = data_142d3f7d0
float temp0_619[0x4] = _mm_fmadd_ps(temp0_618, arg3[0].o, zmm0[0].o)
zmm9 = arg3[0].o
zmm0[0].o = _mm_permute_ps(zmm1[0].o, 0xaa)
zmm1[0].o = _mm_permute_ps(zmm3[0].o, 0xb1)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm0[0].o = data_142d3f7b0
arg3[0].o = _mm_fmadd_ps(arg3[0].o, zmm0[0].o, temp0_619)
zmm10 = zmm0[0].o
float temp0_624[0x4] = _mm_broadcastss_ps(0x3f000000)
zmm1[0].o = _mm_broadcastss_ps(temp0_608)
float temp0_626[0x4] = _mm_permute_ps(zmm11[0].o, 0x1b)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_626)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm4[0].o)
zmm1[0].o = _mm_fmadd_ps(zmm1[0].o, zmm11[0].o, temp0_609)
float temp0_630[0x4] = _mm_permute_ps(temp0_608, 0x55)
zmm0[0].o = _mm_permute_pd(zmm11[0].o, 1)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_630, zmm0[0].o)
zmm0[0].o = _mm_fmadd_ps(zmm0[0].o, zmm9, zmm1[0].o)
zmm1[0].o = _mm_permute_ps(temp0_608, 0xaa)
float temp0_635[0x4] = _mm_permute_ps(zmm11[0].o, 0xb1)
float temp0_637[0x4] =
    _mm_fmadd_ps(__vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_635), zmm10, zmm0[0].o)
arg3[0].o = _mm_fmadd_ps(arg3[0].o, temp0_624, zmm3[0].o)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
zmm1[0].o = _mm_permute_pd(zmm0[0].o, 1)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = __vmovshdup_xmmdq_xmmdq(zmm0[0].o)
zmm0[0].o = zmm0[0].o f+ zmm1[0]
zmm1[0].o = _mm_cmp_ss(0x322bcc77, zmm0[0], 6)
zmm1[0].o = __vandnps_xmmdq_xmmdq_xmmdq(zmm1[0].o, 0xffffffff)
zmm5 = zmm0[0].o f* 0.5f
zmm0[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
zmm3[0].o = zmm0[0].o f* zmm0[0]
zmm3[0].o = _mm_fnmadd_ss(zmm3[0].o, zmm5[0], 0.5f)
zmm3[0].o = _mm_fmadd_ss(zmm3[0].o, zmm0[0], zmm0[0])
zmm0[0].o = zmm3[0].o f* zmm3[0]
zmm0[0].o = _mm_fnmadd_ss(zmm0[0].o, zmm5[0], 0.5f)
zmm0[0].o = _mm_fmadd_ss(zmm0[0].o, zmm3[0], zmm3[0])
zmm0[0].o = _mm_broadcastss_ps(zmm0[0].o)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
zmm1 = _mm256_broadcastss_ps(zmm1[0].o)
zmm0 = _mm256_and_ps(zmm0, zmm1)
zmm1 = __vandnps_ymmqq_ymmqq_memqq(zmm1, data_142fc9280)
arg3 = _mm256_or_ps(zmm0, zmm1)
int64_t rdx = __vpextrq_gpr64q_xmmdq_immb(arg3[0].o, 1)
int64_t rax_7 = arg3[0].q
float temp0_656[0x4] = _mm_fmadd_ps(temp0_637, temp0_624, zmm11[0].o)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_656, temp0_656)
zmm1[0].o = _mm_permute_pd(zmm0[0].o, 1)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = __vmovshdup_xmmdq_xmmdq(zmm0[0].o)
zmm0[0].o = zmm0[0].o f+ zmm1[0]
zmm1[0].o = _mm_cmp_ss(0x322bcc77, zmm0[0], 6)
zmm1[0].o = __vandnps_xmmdq_xmmdq_xmmdq(zmm1[0].o, 0xffffffff)
zmm3[0].o = zmm0[0].o f* 0.5f
zmm0[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
zmm4[0].o = zmm0[0].o f* zmm0[0]
zmm4[0].o = _mm_fnmadd_ss(zmm4[0].o, zmm3[0], 0.5f)
zmm4[0].o = _mm_fmadd_ss(zmm4[0].o, zmm0[0], zmm0[0])
zmm0[0].o = zmm4[0].o f* zmm4[0]
zmm0[0].o = _mm_fnmadd_ss(zmm0[0].o, zmm3[0], 0.5f)
zmm0[0].o = _mm_fmadd_ss(zmm0[0].o, zmm4[0], zmm4[0])
zmm0[0].o = _mm_broadcastss_ps(zmm0[0].o)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_656, zmm0[0].o)
zmm1[0].o = _mm_broadcastss_ps(zmm1[0].o)
zmm0[0].o = __vandps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = __vandnps_xmmdq_xmmdq_memdq(zmm1[0].o, data_142d3f660)
zmm0[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm0[0].o)
zmm3[0].o = _mm_permute_pd(zmm1[0].o, 1)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm3[0].o)
zmm3[0].o = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
zmm1[0].o = zmm1[0].o f+ zmm3[0]
zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
zmm1[0].o = _mm_cmp_ss(zmm3[0].o, zmm1[0], 2)
zmm1[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0xbf800000, 0x3f800000, zmm1[0].o)
zmm1[0].o = _mm_broadcastss_ps(zmm1[0].o)
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
arg1[0xe] = arg3[0].o
arg1[0xf] = zmm4[0].o
zmm0[0].o = zx.o(rax_7.d)
zmm1[0].o = zx.o(rdx.d)
uint32_t result = (rax_7 u>> 0x20).d
arg3[0].o = zx.o(result)
zmm3[0].o = *(arg1 + 0x18)
zmm5 = arg1[1].d
float temp0_684[0x4] = __vinsertps_xmmdq_xmmdq_xmmdq_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x10), zmm0[0].o, 0x20)
float temp0_686[0x4] = __vinsertps_xmmdq_xmmdq_memd_immb(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm5, 0x10), *(arg1 + 0x14), 0x20)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 0x10)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg3[0].o, 0x20)
zmm1[0].o = __vmovsd_xmmdq_memq(arg1[1].q)
arg3[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0x14))
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm5, 0x20)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
arg3[0].o = _mm_fmsub_ps(arg3[0].o, temp0_684, temp0_686)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, arg3[0].o)
zmm5 = _mm_broadcastd_epi32(zx.o((rdx u>> 0x20).d)[0])
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm3[0].o, 0x20)
float temp0_697[0x4] = _mm_fmadd_ps(zmm5, arg3[0].o, zmm1[0].o)
zmm1[0].o = _mm_permute_ps(arg3[0].o, 0xd2)
arg3[0].o = _mm_permute_ps(arg3[0].o, 0xc9)
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
zmm0[0].o = _mm_fmsub_ps(zmm0[0].o, temp0_684, zmm1[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_697, zmm0[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm12, zmm0[0].o)
arg1[8].d = zmm0[0]
*(arg1 + 0x84) = __vextractps_memd_xmmdq_immb(zmm0[0].o, 1)
*(arg1 + 0x88) = __vextractps_memd_xmmdq_immb(zmm0[0].o, 2)
zmm0[0].o = *(arg1 + 0x48)
zmm1[0].o = arg1[4].d
arg3[0].o = _mm_permute_ps(zmm4[0].o, 0xc9)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 0x10)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm3[0].o, *(arg1 + 0x44), 0x20)
float temp0_709[0x4] = _mm_permute_ps(zmm4[0].o, 0xd2)
zmm6 = __vmovsd_xmmdq_memq(arg1[4].q)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(__vmovsd_xmmdq_memq(*(arg1 + 0x44)), zmm1[0].o, 0x20)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_709, zmm1[0].o)
zmm1[0].o = _mm_fmsub_ps(zmm1[0].o, arg3[0].o, zmm3[0].o)
zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm1[0].o)
zmm3[0].o = _mm_permute_ps(zmm4[0].o, 0xff)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm6, zmm0[0].o, 0x20)
zmm3[0].o = _mm_fmadd_ps(zmm3[0].o, zmm1[0].o, zmm0[0].o)
zmm0[0].o = _mm_permute_ps(zmm1[0].o, 0xd2)
zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xc9)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_709, zmm1[0].o)
zmm1[0].o = _mm_fmsub_ps(zmm1[0].o, arg3[0].o, zmm0[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm1[0].o)
zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_602, zmm0[0].o)
*(arg1 + 0x8c) = zmm0[0]
arg1[9].d = __vextractps_memd_xmmdq_immb(zmm0[0].o, 1)
*(arg1 + 0x94) = __vextractps_memd_xmmdq_immb(zmm0[0].o, 2)
zmm4[0].o = _mm_broadcast_ss(*(arg1 + 0xec))
zmm0[0].o = *arg1
float temp0_728[0x4] = _mm_broadcast_ss(arg1[0xe].d)
zmm12 = *(arg1 + 0xc)
zmm13 = *(arg1 + 8)
zmm10 = *(arg1 + 4)
float temp0_732[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(temp0_728, 
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(
        __vinsertps_xmmdq_xmmdq_xmmdq_immb(__vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm12, zmm13, 0x10), 
            zmm10, 0x20), 
        zmm0[0].o, 0x30))
zmm3[0].o = var_1c8_1
float temp0_734[0x4] =
    _mm_fmadd_ps(__vmulps_xmmdq_xmmdq_xmmdq(temp0_732, zmm3[0].o), zmm0[0].o, zmm4[0].o)
zmm4[0].o = _mm_broadcast_ss(*(arg1 + 0xe4))
zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(
    __vinsertps_xmmdq_xmmdq_xmmdq_immb(
        __vinsertps_xmmdq_xmmdq_xmmdq_immb(__vmovsd_xmmdq_memq(*(arg1 + 8)), zmm0[0].o, 0x20), 
        zmm10, 0x30), 
    zmm4[0].o)
zmm11[0].o = zmm9
zmm4[0].o = _mm_fmadd_ps(zmm4[0].o, zmm9, temp0_734)
zmm5 = arg1[3]
zmm9 = *(arg1 + 0x3c)
zmm7 = *(arg1 + 0x38)
zmm1[0].o = *(arg1 + 0x34)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm9, zmm7, 0x10)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm1[0].o, 0x20)
arg3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg3[0].o, zmm5, 0x30)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(_mm_broadcast_ss(arg1[0xf].d), arg3[0].o)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm3[0].o = _mm_broadcast_ss(*(arg1 + 0xfc))
arg3[0].o = _mm_fmadd_ps(arg3[0].o, zmm5, zmm3[0].o)
zmm3[0].o = __vmovsd_xmmdq_memq(*(arg1 + 0x38))
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm5, 0x20)
zmm3[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm3[0].o, zmm1[0].o, 0x30)
float temp0_752[0x4] = _mm_broadcast_ss(*(arg1 + 0xf4))
zmm3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm3[0].o, temp0_752)
zmm3[0].o = _mm_fmadd_ps(zmm3[0].o, zmm11[0].o, arg3[0].o)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm10, zmm0[0].o, 0x10)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm12, 0x20)
zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm13, 0x30)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xe8))
zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg3[0].o)
zmm6 = data_142d3f7b0
zmm0[0].o = _mm_fmadd_ps(zmm0[0].o, zmm6, zmm4[0].o)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm5, 0x10)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm9, 0x20)
zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm7, 0x30)
arg3[0].o = _mm_broadcast_ss(*(arg1 + 0xf8))
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
zmm1[0].o = _mm_fmadd_ps(zmm1[0].o, zmm6, zmm3[0].o)
arg3[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
zmm3[0].o = _mm_permute_pd(arg3[0].o, 1)
arg3[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg3[0].o, zmm3[0].o)
zmm3[0].o = __vmovshdup_xmmdq_xmmdq(arg3[0].o)
arg3[0].o = arg3[0].o f+ zmm3[0]
zmm3[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm3[0].o, zmm3[0].o)
arg3[0].o = _mm_cmp_ss(zmm3[0].o, arg3[0], 2)
arg3[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0xbf800000, 0x3f800000, arg3[0].o)
arg3[0].o = _mm_broadcastss_ps(arg3[0].o)
zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg3[0].o)
arg1[0xa] = zmm0[0].o
arg1[0xb] = zmm1[0].o
_mm256_zeroupper()
return result
