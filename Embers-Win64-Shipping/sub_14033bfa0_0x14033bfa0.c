// 函数: sub_14033bfa0
// 地址: 0x14033bfa0
// 来自: E:\Embers\Embers\Binaries\Win64\Embers-Win64-Shipping.exe

int128_t var_58 = arg15[0].o
int128_t var_68 = arg14[0].o
int128_t var_78 = arg13[0].o
int128_t var_88 = arg12[0].o
int128_t var_a8 = arg11[0].o
int128_t var_b8 = arg10[0].o
int128_t var_c8 = arg9[0].o
int128_t var_d8 = arg8[0].o
int128_t var_e8 = arg7[0].o
float zmm11[0x8] = *arg19
uint64_t result = zx.q(arg18)
float var_240[0x8]
float var_238
float var_230
float var_22c
float var_228
int128_t var_1d0
float var_1ac
float var_1a4
float zmm0[0x8]
float zmm1[0x8]
float zmm4[0x8]
float zmm5[0x4]

if (_mm256_movemask_ps(zmm11) != 0xff)
    if (result.d s>= 2)
        uint64_t rdi_2 = zx.q(result.d)
        int64_t rsi_2 = 1
        arg11[0].o = 0x322bcc77
        arg12[0].o = 0xffffffff
        arg14[0].o = data_142d3f660
        arg15[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg15[0].o, arg15[0].o)
        float var_140_1[0x8] = zmm11
        
        do
            uint64_t rax_26 = zx.q(*(arg3 + (rsi_2 << 1)))
            *(arg4 + sx.q(rax_26.d * arg16 + arg17))
            zmm1[0].o = arg1[sx.q(*(arg4 + sx.q(rax_26.d * arg16 + arg17))) * 3]
            arg13[0].o = arg1[sx.q(*(arg4 + sx.q(rax_26.d * arg16 + arg17))) * 3 + 1]
            arg9[0].o = arg1[sx.q(*(arg4 + sx.q(rax_26.d * arg16 + arg17))) * 3 + 2]
            uint64_t rbx_4 = rax_26 * 0x30
            arg5[0].o = *(arg2 + rbx_4)
            arg7[0].o = *(arg2 + rbx_4 + 0x10)
            arg10[0].o = *(arg2 + rbx_4 + 0x20)
            arg6[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg6[0].o, arg6[0].o)
            float temp0_253[0x8] = _mm256_cmp_ps(arg10, arg6, 1)
            arg6 = _mm256_cmp_ps(arg9, arg6, 1)
            zmm0 = _mm256_and_ps(_mm256_or_ps(temp0_253, arg6), zmm11)
            result = zx.q(_mm256_movemask_ps(zmm0))
            
            if (result.d == 0)
                zmm0[0].o = _mm_permute_ps(zmm1[0].o, 0xff)
                arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg5[0].o)
                float temp0_450[0x4] = _mm_permute_ps(zmm1[0].o, 0)
                arg8[0].o = _mm_permute_ps(arg5[0].o, 0x1b)
                float temp0_453[0x4] = __vmulps_xmmdq_xmmdq_memdq(
                    __vmulps_xmmdq_xmmdq_xmmdq(temp0_450, arg8[0].o), data_142d3f7c0)
                arg6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg6[0].o, temp0_453)
                float temp0_455[0x4] = _mm_permute_ps(zmm1[0].o, 0x55)
                arg8[0].o = _mm_permute_pd(arg5[0].o, 1)
                arg6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(
                    __vmulps_xmmdq_xmmdq_memdq(__vmulps_xmmdq_xmmdq_xmmdq(temp0_455, arg8[0].o), 
                        data_142d3f7d0), 
                    arg6[0].o)
                float temp0_460[0x4] = _mm_permute_ps(zmm1[0].o, 0xaa)
                arg5[0].o = _mm_permute_ps(arg5[0].o, 0xb1)
                arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_460, arg5[0].o)
                arg5[0].o = __vmulps_xmmdq_xmmdq_memdq(arg5[0].o, data_142d3f7b0)
                arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg6[0].o)
                arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg9[0].o, arg7[0].o)
                float temp0_466[0x4] = _mm_permute_ps(zmm1[0].o, 0xc9)
                arg7[0].o = _mm_permute_ps(arg6[0].o, 0xd2)
                zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xd2)
                arg8[0].o = _mm_permute_ps(arg6[0].o, 0xc9)
                arg7[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_466, arg7[0].o)
                arg8[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg8[0].o)
                arg7[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg7[0].o, arg8[0].o)
                arg7[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg7[0].o, arg7[0].o)
                zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg7[0].o)
                zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm0[0].o)
                arg6[0].o = _mm_permute_ps(arg7[0].o, 0xd2)
                arg7[0].o = _mm_permute_ps(arg7[0].o, 0xc9)
                arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_466, arg6[0].o)
                zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg7[0].o)
                zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm1[0].o)
                zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
                zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg13[0].o, zmm0[0].o)
                arg7[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg9[0].o, arg10[0].o)
                arg13[0].o = 0x3f000000
            else
                zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg5[0].o)
                arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg5[0].o, zmm0[0].o)
                float temp0_260[0x4] = _mm_permute_ps(arg6[0].o, 1)
                arg6[0].o = _mm_permute_ps(arg6[0].o, 0x1a)
                arg6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_260, arg6[0].o)
                zmm4[0].o = data_142d3f670
                arg6[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg6[0].o)
                arg11[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg10[0].o, arg6[0].o)
                arg6[0].o = _mm_permute_ps(arg5[0].o, 4)
                float temp0_266[0x4] = _mm_permute_ps(zmm0[0].o, 0x29)
                arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, temp0_266)
                arg5[0].o = _mm_permute_ps(arg5[0].o, 0xff)
                zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0x12)
                zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg5[0].o, zmm0[0].o)
                arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm0[0].o)
                float temp0_272[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(arg10[0].o, arg5[0].o)
                arg5[0].o = _mm_permute_ps(arg10[0].o, 0xc9)
                zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm0[0].o)
                arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg5[0].o, zmm0[0].o)
                zmm0[0].o = _mm_permute_pd(temp0_272, 1)
                arg6[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg15[0].o, arg11[0].o, 1)
                arg8[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, temp0_272, 0x10)
                arg8[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg8[0].o, arg5[0].o, 4)
                arg8 = _mm256_blend_ps(arg6, arg8, 0xf)
                arg6[0].o = _mm256_extractf128_ps(arg6[0].o, 1)
                arg6[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, arg5[0].o, 1)
                arg6[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, arg11[0].o, 2)
                arg6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, temp0_272, 0x60)
                arg6 = _mm256_insertf128_ps(arg8, arg6[0].o, 1)
                arg12 = data_143443080
                float temp0_286[0x8] = _mm256_blend_ps(arg12, zmm0, 1)
                arg8[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_286[0].o, arg5[0].o, 2)
                arg8[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg8[0].o, arg11[0].o, 4)
                temp0_286[0].o = _mm256_extractf128_ps(temp0_286[0].o, 1)
                temp0_286[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg7[0].o, temp0_286[0].o, 8)
                zmm0 = _mm256_insertf128_ps(arg8, temp0_286[0].o, 1)
                float var_1c0_2[0x8] = arg6
                zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm1[0].o)
                arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
                arg7[0].o = _mm_permute_ps(arg6[0].o, 0xc1)
                arg6[0].o = _mm_permute_ps(arg6[0].o, 0xda)
                arg6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg7[0].o, arg6[0].o)
                arg6[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg6[0].o)
                arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg9[0].o, arg6[0].o)
                arg7[0].o = _mm_permute_ps(zmm1[0].o, 4)
                arg8[0].o = _mm_permute_ps(zmm0[0].o, 0x29)
                arg7[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg7[0].o, arg8[0].o)
                zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xff)
                zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0x12)
                zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
                zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg7[0].o, zmm0[0].o)
                arg8[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg9[0].o, zmm1[0].o)
                zmm1[0].o = _mm_permute_ps(arg9[0].o, 0xc9)
                zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg7[0].o, zmm0[0].o)
                zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
                zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg15[0].o, arg6[0].o, 1)
                arg7[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg8[0].o, 0x10)
                zmm1[0].o = _mm256_extractf128_ps(zmm1[0].o, 1)
                zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 1)
                zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg6[0].o, 2)
                zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg8[0].o, 0x60)
                arg8[0].o = _mm_permute_pd(arg8[0].o, 1)
                arg7[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg7[0].o, zmm0[0].o, 4)
                arg8 = _mm256_blend_ps(arg12, arg8, 1)
                zmm0[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg8[0].o, zmm0[0].o, 2)
                zmm0[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg6[0].o, 4)
                arg6[0].o = __vpcmpeqd_xmmdq_xmmdq_xmmdq(zmm11[0].o, arg15[0].o)
                uint32_t var_100_1[0x4] = arg6[0].o
                arg6[0].o = _mm256_extractf128_ps(arg8[0].o, 1)
                arg6[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg13[0].o, arg6[0].o, 8)
                zmm4[0].o = _mm_permute_ps(arg11[0].o, 0)
                zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg7[0].o, zmm4[0].o)
                arg8[0].o = _mm_permute_ps(arg5[0].o, 0xaa)
                arg8[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg8[0].o)
                zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg8[0].o)
                arg8[0].o = _mm_permute_ps(temp0_272, 0)
                arg8[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg8[0].o)
                zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg8[0].o)
                arg8[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, arg15[0].o)
                zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg8[0].o)
                arg5[0].o = _mm_permute_ps(arg5[0].o, 0)
                arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg7[0].o, arg5[0].o)
                float temp0_336[0x4] = _mm_permute_ps(temp0_272, 0x55)
                float temp0_337[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_336)
                arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, temp0_337)
                float temp0_339[0x4] = _mm_broadcast_ss(var_1ac)
                float temp0_340[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_339)
                arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, temp0_340)
                float temp0_342[0x4] = _mm_broadcast_ss(var_1a4)
                float temp0_343[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, temp0_342)
                arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, temp0_343)
                float temp0_345[0x4] = _mm_broadcast_ss(zmm0[0])
                float temp0_346[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(arg7[0].o, temp0_345)
                arg8[0].o = _mm_broadcast_ss(zmm0[2])
                arg8[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg8[0].o)
                float temp0_349[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(temp0_346, arg8[0].o)
                arg8[0].o = _mm_broadcast_ss(zmm0[1])
                arg8[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg8[0].o)
                float temp0_352[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(temp0_349, arg8[0].o)
                arg8[0].o = _mm_broadcast_ss(zmm0[3])
                arg8[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, arg8[0].o)
                float temp0_355[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(temp0_352, arg8[0].o)
                arg8[0].o = _mm_broadcast_ss(zmm0[4])
                arg7[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg7[0].o, arg8[0].o)
                arg8[0].o = _mm_broadcast_ss(zmm0[6])
                zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg8[0].o)
                arg8[0].o = _mm256_extractf128_ps(zmm11[0].o, 1)
                arg8[0].o = __vpcmpeqd_xmmdq_xmmdq_xmmdq(arg8[0].o, arg15[0].o)
                int128_t var_110_1 = arg8[0].o
                zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg7[0].o, zmm0[0].o)
                arg7[0].o = _mm_broadcast_ss(zmm0[5])
                zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg7[0].o)
                zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
                zmm1[0].o = _mm_broadcast_ss(zmm0[7])
                zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm1[0].o)
                zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
                arg9[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg9[0].o, arg10[0].o)
                arg6[0].o = __vmovshdup_xmmdq_xmmdq(zmm4[0].o)
                arg7[0].o = zx.o(__vextractps_gpr32_xmmdq_immb(arg5[0].o, 0))
                arg8[0].o = zx.o(__vextractps_gpr32_xmmdq_immb(temp0_355, 0))
                zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_355, arg8[0].o, 1)
                arg10 = _mm256_insertf128_ps(zmm1, zmm0[0].o, 1)
                zmm0[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg5[0].o, arg7[0].o, 1)
                zmm0 = _mm256_insertf128_ps(zmm4, zmm0[0].o, 1)
                var_240 = zmm0
                zmm0[0].o = zmm4[0].o f* zmm4[0]
                arg6[0].o = arg6[0].o f* arg6[0]
                zmm0[0].o = zmm0[0].o f+ arg6[0]
                arg6[0].o = _mm_permute_pd(zmm4[0].o, 1)
                arg6[0].o = arg6[0].o f* arg6[0]
                zmm0[0].o = zmm0[0].o f+ arg6[0]
                arg6[0].o = __vmovshdup_xmmdq_xmmdq(arg5[0].o)
                arg5[0].o = _mm_permute_pd(arg5[0].o, 1)
                arg7[0].o = arg7[0].o f* arg7[0]
                arg6[0].o = arg6[0].o f* arg6[0]
                arg6[0].o = arg7[0].o f+ arg6[0]
                arg7[0].o = __vmovshdup_xmmdq_xmmdq(temp0_355)
                zmm5 = _mm_permute_pd(temp0_355, 1)
                arg5[0].o = arg5[0].o f* arg5[0]
                arg6[0].o = arg6[0].o f+ arg5[0]
                arg5[0].o = arg8[0].o f* arg8[0]
                arg7[0].o = arg7[0].o f* arg7[0]
                arg5[0].o = arg5[0].o f+ arg7[0]
                arg5[0].o = arg5[0].o f+ (zmm5 f* zmm5[0])[0]
                zmm1[0].o = 0xb22bcc77
                zmm5 = zmm0[0].o f+ -9.99999994e-09f
                arg7[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
                arg13[0].o = 0x3f000000
                zmm0[0].o = zmm0[0].o f* 0.5f
                arg8[0].o = arg7[0].o f* arg7[0]
                arg8[0].o = zmm0[0].o f* arg8[0]
                arg8[0].o = 0x3f000000 f- arg8[0]
                arg8[0].o = arg7[0].o f* arg8[0]
                arg7[0].o = arg7[0].o f+ arg8[0]
                arg8[0].o = arg7[0].o f* arg7[0]
                zmm0[0].o = zmm0[0].o f* arg8[0]
                zmm0[0].o = 0x3f000000 f- zmm0[0]
                zmm0[0].o = arg7[0].o f* zmm0[0]
                zmm0[0].o = arg7[0].o f+ zmm0[0]
                arg11[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg11[0].o, arg11[0].o)
                float temp0_384[0x4] = _mm_cmp_ss(arg11[0].o, zmm5[0], 2)
                arg7[0].o = 0x3f800000
                arg14[0].o = 0x3f800000
                zmm0[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0x3f800000, zmm0[0].o, temp0_384)
                zmm5 = arg6[0].o f+ -9.99999994e-09f
                arg7[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(arg6[0].o, arg6[0])
                arg6[0].o = arg6[0].o f* 0.5f
                arg8[0].o = arg7[0].o f* arg7[0]
                arg8[0].o = arg6[0].o f* arg8[0]
                arg8[0].o = 0x3f000000 f- arg8[0]
                arg8[0].o = arg7[0].o f* arg8[0]
                arg7[0].o = arg7[0].o f+ arg8[0]
                arg8[0].o = arg7[0].o f* arg7[0]
                arg6[0].o = arg6[0].o f* arg8[0]
                arg6[0].o = 0x3f000000 f- arg6[0]
                arg6[0].o = arg7[0].o f* arg6[0]
                arg6[0].o = arg7[0].o f+ arg6[0]
                float temp0_387[0x4] = _mm_cmp_ss(arg11[0].o, zmm5[0], 2)
                arg6[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0x3f800000, arg6[0].o, temp0_387)
                zmm5 = arg5[0].o f+ -9.99999994e-09f
                arg7[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(arg5[0].o, arg5[0])
                arg5[0].o = arg5[0].o f* 0.5f
                arg8[0].o = arg7[0].o f* arg7[0]
                arg8[0].o = arg5[0].o f* arg8[0]
                arg8[0].o = 0x3f000000 f- arg8[0]
                arg8[0].o = arg7[0].o f* arg8[0]
                arg7[0].o = arg7[0].o f+ arg8[0]
                arg8[0].o = arg7[0].o f* arg7[0]
                arg5[0].o = arg5[0].o f* arg8[0]
                arg5[0].o = 0x3f000000 f- arg5[0]
                arg5[0].o = arg7[0].o f* arg5[0]
                arg5[0].o = arg7[0].o f+ arg5[0]
                float temp0_390[0x4] = _mm_cmp_ss(arg11[0].o, zmm5[0], 2)
                arg5[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0x3f800000, arg5[0].o, temp0_390)
                int224_t var_220_2 = arg10[0].28
                zmm1[0].o = zmm0[0].o f* zmm4[0]
                zmm4[0].o = zmm0[0].o f* var_240[1]
                zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm4[0].o, 0x10)
                zmm0[0].o = zmm0[0].o f* var_238
                zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 0x20)
                zmm1[0].o = arg6[0].o f* var_230
                zmm4[0].o = arg6[0].o f* var_22c
                zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm4[0].o, 0x10)
                arg6[0].o = arg6[0].o f* var_228
                zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg6[0].o, 0x20)
                arg6[0].o = arg5[0].o f* var_220_2.d
                zmm4[0].o = arg5[0].o f* var_220_2:4.d
                arg6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, zmm4[0].o, 0x10)
                arg5[0].o = arg5[0].o f* var_220_2:8.d
                arg5[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, arg5[0].o, 0x20)
                int128_t var_150_1 = arg9[0].o
                arg6[0].o = _mm_cmp_ps(arg15[0].o, arg9[0].o, 2)
                arg6[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm0[0].o)
                arg6[0].o = __vpmovzxwd_xmmdq_xmmq(arg6[0].q)
                arg6[0].o = __vpslld_xmmdq_xmmdq_immb(arg6[0].o, 0x1f)
                zmm4 = data_1434431a0
                arg6 = __vblendvps_ymmqq_ymmqq_memqq_ymmqq(zmm4, data_1434430a0, arg6)
                zmm4[0].o = _mm_permute_ps(arg6[0].o, 0)
                zmm4 = _mm256_insertf128_ps(zmm4, zmm4[0].o, 1)
                arg10 = _mm256_mul_ps(zmm4, zmm0)
                zmm0[0].o = __vmovshdup_xmmdq_xmmdq(arg10[0].o)
                arg15[0].o = _mm_permute_pd(arg10[0].o, 1)
                var_240[0] = arg10[0]
                int128_t var_120_1 = zmm0[0].o
                var_240[1] = zmm0[0]
                var_238 = arg15[0]
                zmm0[0].o = _mm_permute_ps(arg6[0].o, 0x55)
                zmm0 = _mm256_insertf128_ps(zmm0, zmm0[0].o, 1)
                zmm1 = _mm256_mul_ps(zmm0, zmm1)
                float temp0_411[0x4] = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
                arg11[0].o = _mm_permute_pd(zmm1[0].o, 1)
                var_230 = zmm1[0]
                var_22c = temp0_411[0]
                var_228 = arg11[0]
                zmm0[0].o = _mm_permute_ps(arg6[0].o, 0xaa)
                arg5 = _mm256_mul_ps(_mm256_insertf128_ps(zmm0, zmm0[0].o, 1), arg5)
                arg9 = data_142fc9300
                float temp0_416[0x8] = _mm256_blend_ps(arg10, arg9, 0xf8)
                arg12 = data_142fc9320
                zmm0 = _mm256_and_ps(temp0_416, arg12)
                zmm11 = data_1434431c0
                zmm0 = _mm256_cmp_ps(zmm0, zmm11, 2)
                arg6[0].o = __vorps_xmmdq_xmmdq_memdq(zmm0[0].o, var_100_1)
                zmm0[0].o = _mm256_extractf128_ps(zmm0[0].o, 1)
                zmm4[0].o = var_110_1
                zmm0[0].o |= zmm4[0].o
                zmm0[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm0[0].o)
                arg6[0].o = __vmovshdup_xmmdq_xmmdq(arg5[0].o)
                zmm0[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
                result = zx.q(__vpmovmskb_gpr32d_xmmdq(zmm0[0].o))
                arg7[0].o = _mm_permute_pd(arg5[0].o, 1)
                var_220_2.d = arg5[0]
                var_220_2:4.d = arg6[0]
                var_220_2:8.d = arg7[0]
                
                if (result.b == 0xff)
                label_14033d0d0:
                    arg14[0].o = data_142d3f660
                    zmm0[0].o = arg14[0].o
                    zmm11 = var_140_1
                    arg11[0].o = 0x322bcc77
                    arg12[0].o = 0xffffffff
                else
                    arg14[0].o = zmm4[0].o
                    zmm0[0].o = zx.o(0)
                    zmm0[0].o = __vpcmpeqd_xmmdq_xmmdq_memdq(zx.o(0), var_140_1[0].o)
                    zmm4 = _mm256_cmp_ps(_mm256_and_ps(_mm256_blend_ps(zmm1, arg9, 0xf8), arg12), 
                        zmm11, 2)
                    arg8[0].o = _mm256_extractf128_ps(zmm4[0].o, 1)
                    arg8[0].o |= arg14[0].o
                    zmm0[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm0[0].o)
                    zmm0[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg8[0].o)
                    zmm0[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
                    result = zx.q(__vpmovmskb_gpr32d_xmmdq(zmm0[0].o))
                    
                    if (result.b == 0xff)
                        goto label_14033d0d0
                    
                    zmm0[0].o = zx.o(0)
                    zmm0[0].o = __vpcmpeqd_xmmdq_xmmdq_memdq(zx.o(0), var_140_1[0].o)
                    arg8 = _mm256_cmp_ps(_mm256_and_ps(_mm256_blend_ps(arg5, arg9, 0xf8), arg12), 
                        zmm11, 2)
                    zmm4[0].o = _mm256_extractf128_ps(arg8[0].o, 1)
                    zmm4[0].o |= arg14[0].o
                    zmm0[0].o = __vorps_xmmdq_xmmdq_xmmdq(arg8[0].o, zmm0[0].o)
                    zmm0[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm4[0].o)
                    zmm0[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
                    result = zx.q(__vpmovmskb_gpr32d_xmmdq(zmm0[0].o))
                    
                    if (result.b == 0xff)
                        goto label_14033d0d0
                    
                    arg12 = var_140_1
                    zmm0[0].o = arg10[0].o f+ temp0_411[0]
                    zmm0[0].o = arg7[0].o f+ zmm0[0]
                    
                    if (zmm0[0].o f<= 0f)
                        temp0_411 f- arg10[0]
                        int64_t r10_1
                        r10_1.b = temp0_411 f> arg10[0]
                        int64_t rax_35 = 0
                        
                        if (temp0_411 f> arg10[0])
                            rax_35 = 0x14
                        
                        if (arg7[0].o f> *(&var_240 + rax_35))
                            r10_1 = 2
                        
                        int64_t r14_4 = sx.q(*(&data_14344321c + (r10_1 << 2)))
                        int64_t r12_2 = sx.q(*(&data_14344321c + (r14_4 << 2)))
                        zmm0[0].o = var_240[zx.q((r10_1 * 5).d)]
                        zmm0[0].o = zmm0[0].o f- var_240[sx.q((r14_4 * 5).d)]
                        zmm0[0].o = zmm0[0].o f- var_240[sx.q((r12_2 * 5).d)]
                        zmm1[0].o = 0x3f800000
                        arg5[0].o = 0x3f800000
                        zmm0[0].o = zmm0[0].o f+ 1f
                        zmm0[0].o = __vsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
                        zmm0[0].o = 0x3f800000 f/ zmm0[0]
                        zmm1[0].o = zmm0[0].o f* 0.5f
                        zmm0[0].o = 0x3f800000 f/ zmm0[0]
                        zmm0[0].o = zmm0[0].o f* 0.5f
                        *(&var_1d0 + (r10_1 << 2)) = zmm0[0]
                        zmm0[0].o = var_240[sx.q((r14_4 + (r10_1 << 2)).d)]
                        zmm0[0].o = zmm0[0].o f+ var_240[sx.q((r10_1 + (r14_4 << 2)).d)]
                        zmm0[0].o = zmm0[0].o f* zmm1[0]
                        *(&var_1d0 + (r14_4 << 2)) = zmm0[0]
                        zmm0[0].o = var_240[sx.q((r12_2 + (r10_1 << 2)).d)]
                        zmm0[0].o = zmm0[0].o f+ var_240[sx.q((r10_1 + (r12_2 << 2)).d)]
                        zmm0[0].o = zmm1[0].o f* zmm0[0]
                        arg5[0].o = var_240[sx.q((r12_2 + (r14_4 << 2)).d)]
                        result = sx.q((r14_4 + (r12_2 << 2)).d)
                        arg5[0].o = arg5[0].o f- var_240[result]
                        *(&var_1d0 + (r12_2 << 2)) = zmm0[0]
                        zmm0[0].o = zmm1[0].o f* arg5[0]
                        float var_1c4_2 = zmm0[0]
                        zmm0[0].o = var_1d0
                    else
                        zmm4[0].o = 0x3f800000
                        zmm0[0].o = zmm0[0].o f+ 1f
                        zmm0[0].o = __vsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
                        zmm0[0].o = 0x3f800000 f/ zmm0[0]
                        zmm4[0].o = zmm0[0].o f* 0.5f
                        arg6[0].o = arg11[0].o f- arg6[0]
                        arg6[0].o = arg6[0].o f* zmm4[0]
                        arg5[0].o = arg5[0].o f- arg15[0]
                        arg5[0].o = arg5[0].o f* zmm4[0]
                        arg5[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, arg5[0].o, 0x10)
                        arg6[0].o = var_120_1
                        zmm1[0].o = arg6[0].o f- zmm1[0]
                        zmm1[0].o = zmm1[0].o f* zmm4[0]
                        zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg5[0].o, zmm1[0].o, 0x20)
                        zmm0[0].o = 0x3f800000 f/ zmm0[0]
                        zmm0[0].o = zmm0[0].o f* 0.5f
                        zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 0x30)
                    
                    zmm11 = arg12
                    arg11[0].o = 0x322bcc77
                    arg12[0].o = 0xffffffff
                    arg14[0].o = data_142d3f660
                
                arg15[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg15[0].o, arg15[0].o)
                arg7[0].o = var_150_1
                zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
                arg5[0].o = _mm_permute_pd(zmm1[0].o, 1)
                zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg5[0].o)
                arg5[0].o = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
                zmm1[0].o = zmm1[0].o f+ arg5[0]
                arg5[0].o = _mm_cmp_ss(arg11[0].o, zmm1[0], 6)
                arg5[0].o = __vandnps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg12[0].o)
                arg6[0].o = zmm1[0].o f* 0.5f
                zmm1[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm1[0].o, zmm1[0])
                zmm4[0].o = zmm1[0].o f* zmm1[0]
                zmm4[0].o = zmm4[0].o f* arg6[0]
                zmm4[0].o = 0x3f000000 f- zmm4[0]
                zmm4[0].o = zmm1[0].o f* zmm4[0]
                zmm1[0].o = zmm1[0].o f+ zmm4[0]
                zmm4[0].o = zmm1[0].o f* zmm1[0]
                arg6[0].o = arg6[0].o f* zmm4[0]
                arg6[0].o = 0x3f000000 f- arg6[0]
                arg6[0].o = zmm1[0].o f* arg6[0]
                zmm1[0].o = zmm1[0].o f+ arg6[0]
                zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0)
                zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
                zmm1[0].o = _mm_permute_ps(arg5[0].o, 0)
                zmm0[0].o = __vandps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
                zmm1[0].o = __vandnps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg14[0].o)
                arg5[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
                zmm0[0].o = __vmovsd_xmmdq_memq(var_220_2:0x10.q)
                zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm0[0].o, var_220_2:0x18.d, 0x28)
            
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg5[0].o)
            arg6[0].o = _mm_permute_pd(zmm0[0].o, 1)
            zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg6[0].o)
            arg6[0].o = __vmovshdup_xmmdq_xmmdq(zmm0[0].o)
            zmm0[0].o = zmm0[0].o f+ arg6[0]
            arg6[0].o = _mm_cmp_ss(arg11[0].o, zmm0[0], 6)
            arg6[0].o = __vandnps_xmmdq_xmmdq_xmmdq(arg6[0].o, arg12[0].o)
            zmm4[0].o = zmm0[0].o f* arg13[0]
            zmm0[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
            zmm0[0].o = zmm0[0].o
                f+ (zmm0[0].o f* (arg13[0].o f- (zmm0[0].o f* zmm0[0] f* zmm4[0])[0])[0])[0]
            zmm4[0].o = zmm4[0].o f* (zmm0[0].o f* zmm0[0])[0]
            zmm4[0].o = arg13[0].o f- zmm4[0]
            zmm4[0].o = zmm0[0].o f* zmm4[0]
            zmm0[0].o = zmm0[0].o f+ zmm4[0]
            zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg5[0].o, zmm0[0].o)
            arg5[0].o = _mm_permute_ps(arg6[0].o, 0)
            zmm0[0].o = __vandps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg5[0].o)
            arg5[0].o = __vandnps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg14[0].o)
            zmm0[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg5[0].o)
            arg1[rax_26 * 3] = zmm0[0].o
            arg1[rax_26 * 3 + 1] = zmm1[0].o
            arg1[rax_26 * 3 + 2] = arg7[0].o
            rsi_2 += 1
        while (rdi_2 != rsi_2)
else if (result.d s>= 2)
    uint64_t rdi_1 = zx.q(result.d)
    int64_t rsi_1 = 1
    arg9[0].o = 0x322bcc77
    arg8[0].o = 0xffffffff
    arg10[0].o = 0x3f000000
    zmm11[0].o = data_142d3f660
    
    do
        uint64_t rax_1 = zx.q(*(arg3 + (rsi_1 << 1)))
        *(arg4 + sx.q(rax_1.d * arg16 + arg17))
        arg11[0].o = arg1[sx.q(*(arg4 + sx.q(rax_1.d * arg16 + arg17))) * 3]
        arg12[0].o = arg1[sx.q(*(arg4 + sx.q(rax_1.d * arg16 + arg17))) * 3 + 1]
        arg14[0].o = arg1[sx.q(*(arg4 + sx.q(rax_1.d * arg16 + arg17))) * 3 + 2]
        uint64_t rbx_2 = rax_1 * 0x30
        zmm0[0].o = *(arg2 + rbx_2)
        arg13[0].o = *(arg2 + rbx_2 + 0x10)
        arg15[0].o = *(arg2 + rbx_2 + 0x20)
        arg5[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg5[0].o)
        float temp0_2[0x8] = _mm256_cmp_ps(arg15, arg5, 1)
        arg5 = _mm256_cmp_ps(arg14, arg5, 1)
        zmm1 = _mm256_or_ps(temp0_2, arg5)
        arg5[0].o = _mm256_extractf128_ps(zmm1[0].o, 1)
        zmm1[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg5[0].o)
        zmm1[0].o = __vpacksswb_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
        result = zx.q(__vpmovmskb_gpr32d_xmmdq(zmm1[0].o))
        
        if (result.b == 0)
            zmm1[0].o = _mm_permute_ps(arg11[0].o, 0xff)
            arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
            arg6[0].o = _mm_permute_ps(arg11[0].o, 0)
            zmm4[0].o = _mm_permute_ps(zmm0[0].o, 0x1b)
            arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm4[0].o)
            arg6[0].o = __vmulps_xmmdq_xmmdq_memdq(arg6[0].o, data_142d3f7c0)
            arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg6[0].o)
            arg6[0].o = _mm_permute_ps(arg11[0].o, 0x55)
            zmm4[0].o = _mm_permute_pd(zmm0[0].o, 1)
            arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm4[0].o)
            arg6[0].o = __vmulps_xmmdq_xmmdq_memdq(arg6[0].o, data_142d3f7d0)
            arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg6[0].o, arg5[0].o)
            arg6[0].o = _mm_permute_ps(arg11[0].o, 0xaa)
            zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xb1)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm0[0].o)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_memdq(zmm0[0].o, data_142d3f7b0)
            zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg5[0].o)
            arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg14[0].o, arg13[0].o)
            arg6[0].o = _mm_permute_ps(arg11[0].o, 0xc9)
            zmm4[0].o = _mm_permute_ps(arg5[0].o, 0xd2)
            float temp0_206[0x4] = _mm_permute_ps(arg11[0].o, 0xd2)
            arg7[0].o = _mm_permute_ps(arg5[0].o, 0xc9)
            zmm4[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm4[0].o)
            arg7[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_206, arg7[0].o)
            zmm4[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg7[0].o)
            zmm4[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm4[0].o)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm4[0].o)
            zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, zmm1[0].o)
            arg5[0].o = _mm_permute_ps(zmm4[0].o, 0xd2)
            zmm4[0].o = _mm_permute_ps(zmm4[0].o, 0xc9)
            arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, arg5[0].o)
            arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_206, zmm4[0].o)
            arg5[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg6[0].o)
            zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg5[0].o)
            zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg12[0].o, zmm1[0].o)
            arg14[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg14[0].o, arg15[0].o)
        else
            zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
            arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
            arg6[0].o = _mm_permute_ps(arg5[0].o, 1)
            arg5[0].o = _mm_permute_ps(arg5[0].o, 0x1a)
            arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg6[0].o, arg5[0].o)
            zmm4[0].o = data_142d3f670
            arg5[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, arg5[0].o)
            float temp0_15[0x4] = __vmulps_xmmdq_xmmdq_xmmdq(arg15[0].o, arg5[0].o)
            arg5[0].o = _mm_permute_ps(zmm0[0].o, 4)
            arg6[0].o = _mm_permute_ps(zmm1[0].o, 0x29)
            arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg6[0].o)
            zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0xff)
            zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0x12)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
            zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, zmm0[0].o)
            arg9[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg15[0].o, zmm1[0].o)
            zmm1[0].o = _mm_permute_ps(arg15[0].o, 0xc9)
            zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(arg5[0].o, zmm0[0].o)
            zmm11[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
            zmm0[0].o = _mm_permute_pd(arg9[0].o, 1)
            zmm1[0].o = __vxorps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm1[0].o)
            zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, temp0_15, 1)
            arg5[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg9[0].o, 0x10)
            arg5[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg5[0].o, zmm11[0].o, 4)
            float temp0_32[0x8] = _mm256_blend_ps(zmm1, arg5, 0xf)
            zmm1[0].o = _mm256_extractf128_ps(zmm1[0].o, 1)
            zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm11[0].o, 1)
            zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, temp0_15, 2)
            zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg9[0].o, 0x60)
            zmm1 = _mm256_insertf128_ps(temp0_32, zmm1[0].o, 1)
            arg7 = data_143443080
            float temp0_38[0x8] = _mm256_blend_ps(arg7, zmm0, 1)
            temp0_32[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_38[0].o, zmm11[0].o, 2)
            temp0_32[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_32[0].o, temp0_15, 4)
            temp0_38[0].o = _mm256_extractf128_ps(temp0_38[0].o, 1)
            temp0_38[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg13[0].o, temp0_38[0].o, 8)
            zmm0 = _mm256_insertf128_ps(temp0_32, temp0_38[0].o, 1)
            float var_1c0_1[0x8] = zmm1
            zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg11[0].o, arg11[0].o)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg11[0].o, zmm0[0].o)
            temp0_32[0].o = _mm_permute_ps(zmm1[0].o, 0xc1)
            zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0xda)
            zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, zmm1[0].o)
            zmm1[0].o = __vsubps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm1[0].o)
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg14[0].o, zmm1[0].o)
            temp0_32[0].o = _mm_permute_ps(arg11[0].o, 4)
            arg6[0].o = _mm_permute_ps(zmm0[0].o, 0x29)
            temp0_32[0].o = __vmulps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, arg6[0].o)
            arg6[0].o = _mm_permute_ps(arg11[0].o, 0xff)
            zmm0[0].o = _mm_permute_ps(zmm0[0].o, 0x12)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, zmm0[0].o)
            arg6[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, zmm0[0].o)
            arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg14[0].o, arg6[0].o)
            zmm4[0].o = _mm_permute_ps(arg14[0].o, 0xc9)
            zmm0[0].o = __vsubps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, zmm0[0].o)
            temp0_32[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm4[0].o, zmm0[0].o)
            arg11[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg11[0].o, arg11[0].o)
            zmm0[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg11[0].o, zmm1[0].o, 1)
            zmm4[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg6[0].o, 0x10)
            zmm0[0].o = _mm256_extractf128_ps(zmm0[0].o, 1)
            zmm0[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, temp0_32[0].o, 1)
            zmm0[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, zmm1[0].o, 2)
            zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm0[0].o, arg6[0].o, 0x60)
            arg8[0].o = _mm_permute_pd(arg6[0].o, 1)
            arg6[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(zmm4[0].o, temp0_32[0].o, 4)
            float temp0_71[0x8] = _mm256_blend_ps(arg7, arg8, 1)
            temp0_32[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_71[0].o, temp0_32[0].o, 2)
            arg8[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_32[0].o, zmm1[0].o, 4)
            zmm1[0].o = _mm256_extractf128_ps(temp0_71[0].o, 1)
            zmm1[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(arg12[0].o, zmm1[0].o, 8)
            temp0_32[0].o = _mm_permute_ps(temp0_15, 0)
            temp0_32[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, temp0_32[0].o)
            temp0_71[0].o = _mm_permute_ps(zmm11[0].o, 0xaa)
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg8[0].o, temp0_71[0].o)
            temp0_32[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_71[0].o = _mm_permute_ps(arg9[0].o, 0)
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_71[0].o)
            temp0_32[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg11[0].o)
            arg11[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg11[0].o, arg11[0].o)
            arg12[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_32[0].o = _mm_permute_ps(zmm11[0].o, 0)
            temp0_32[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, temp0_32[0].o)
            temp0_71[0].o = _mm_permute_ps(arg9[0].o, 0x55)
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg8[0].o, temp0_71[0].o)
            temp0_32[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_71[0].o = _mm_broadcast_ss(var_1ac)
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_71[0].o)
            temp0_32[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_71[0].o = _mm_broadcast_ss(var_1a4)
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_71[0].o)
            float temp0_97[0x4] = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_32[0].o = _mm_broadcast_ss(zmm0[0])
            temp0_32[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, temp0_32[0].o)
            temp0_71[0].o = _mm_broadcast_ss(zmm0[2])
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg8[0].o, temp0_71[0].o)
            temp0_32[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_71[0].o = _mm_broadcast_ss(zmm0[1])
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, temp0_71[0].o)
            temp0_32[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_71[0].o = _mm_broadcast_ss(zmm0[3])
            temp0_71[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_71[0].o)
            temp0_71[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, temp0_71[0].o)
            temp0_32[0].o = _mm_broadcast_ss(zmm0[4])
            temp0_32[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg6[0].o, temp0_32[0].o)
            arg6[0].o = _mm_broadcast_ss(zmm0[6])
            arg6[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg8[0].o, arg6[0].o)
            temp0_32[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, arg6[0].o)
            arg6[0].o = _mm_broadcast_ss(zmm0[5])
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg6[0].o)
            zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(temp0_32[0].o, zmm0[0].o)
            temp0_32[0].o = _mm_broadcast_ss(zmm0[7])
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm1[0].o, temp0_32[0].o)
            zmm0[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
            arg14[0].o = __vmulps_xmmdq_xmmdq_xmmdq(arg14[0].o, arg15[0].o)
            zmm1[0].o = __vmovshdup_xmmdq_xmmdq(arg12[0].o)
            int32_t temp0_122 = __vextractps_gpr32_xmmdq_immb(temp0_97, 0)
            temp0_32[0].o = _mm_permute_pd(arg12[0].o, 1)
            arg6[0].o = zx.o(temp0_122)
            arg8[0].o = zx.o(__vextractps_gpr32_xmmdq_immb(temp0_71[0].o, 0))
            arg9[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_71[0].o, arg8[0].o, 1)
            zmm0 = _mm256_insertf128_ps(arg9, zmm0[0].o, 1)
            arg7[0].o = __vblendps_xmmdq_xmmdq_xmmdq_immb(temp0_97, arg6[0].o, 1)
            arg7 = _mm256_insertf128_ps(arg12, arg7[0].o, 1)
            var_240 = arg7
            arg7[0].o = __vmovshdup_xmmdq_xmmdq(temp0_97)
            zmm5 = _mm_permute_pd(temp0_97, 1)
            int224_t var_220_1 = zmm0[0].28
            zmm0[0].o = arg12[0].o f* arg12[0]
            zmm1[0].o = zmm1[0].o f* zmm1[0]
            zmm0[0].o = zmm0[0].o f+ zmm1[0]
            zmm1[0].o = __vmovshdup_xmmdq_xmmdq(temp0_71[0].o)
            temp0_71[0].o = _mm_permute_pd(temp0_71[0].o, 1)
            temp0_32[0].o = temp0_32[0].o f* temp0_32[0]
            zmm0[0].o = zmm0[0].o f+ temp0_32[0]
            temp0_32[0].o = arg6[0].o f* arg6[0]
            arg6[0].o = arg7[0].o f* arg7[0]
            temp0_32[0].o = temp0_32[0].o f+ arg6[0]
            arg6[0].o = zmm5 f* zmm5[0]
            temp0_32[0].o = temp0_32[0].o f+ arg6[0]
            arg6[0].o = arg8[0].o f* arg8[0]
            zmm1[0].o = zmm1[0].o f* zmm1[0]
            zmm1[0].o = arg6[0].o f+ zmm1[0]
            arg6[0].o = temp0_71[0].o f* temp0_71[0]
            zmm1[0].o = zmm1[0].o f+ arg6[0]
            arg6[0].o = 0xb22bcc77
            arg7[0].o = 0xb22bcc77
            arg6[0].o = zmm0[0].o f+ -9.99999994e-09f
            temp0_71[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
            zmm0[0].o = zmm0[0].o f* 0.5f
            temp0_71[0].o = temp0_71[0].o f+ (temp0_71[0].o
                f* (0x3f000000 - (zmm0[0].o f* (temp0_71[0].o f* temp0_71[0])[0])[0])[0])[0]
            zmm0[0].o = zmm0[0].o f* (temp0_71[0].o f* temp0_71[0])[0]
            zmm0[0].o = 0x3f000000 f- zmm0[0]
            zmm0[0].o = temp0_71[0].o f* zmm0[0]
            zmm0[0].o = temp0_71[0].o f+ zmm0[0]
            arg9[0].o = __vxorps_xmmdq_xmmdq_xmmdq(arg9[0].o, arg9[0].o)
            arg6[0].o = _mm_cmp_ss(arg9[0].o, arg6[0], 2)
            temp0_71[0].o = 0x3f800000
            arg8[0].o = 0x3f800000
            zmm0[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0x3f800000, zmm0[0].o, arg6[0].o)
            arg6[0].o = temp0_32[0].o f+ -9.99999994e-09f
            temp0_71[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(temp0_32[0].o, temp0_32[0])
            temp0_32[0].o = temp0_32[0].o f* 0.5f
            temp0_71[0].o = temp0_71[0].o f+ (temp0_71[0].o
                f* (0x3f000000 - (temp0_32[0].o f* (temp0_71[0].o f* temp0_71[0])[0])[0])[0])[0]
            temp0_32[0].o = temp0_32[0].o f* (temp0_71[0].o f* temp0_71[0])[0]
            temp0_32[0].o = 0x3f000000 f- temp0_32[0]
            temp0_32[0].o = temp0_71[0].o f* temp0_32[0]
            temp0_32[0].o = temp0_71[0].o f+ temp0_32[0]
            arg6[0].o = _mm_cmp_ss(arg9[0].o, arg6[0], 2)
            temp0_32[0].o =
                __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0x3f800000, temp0_32[0].o, arg6[0].o)
            arg6[0].o = zmm1[0].o f+ -9.99999994e-09f
            temp0_71[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm1[0].o, zmm1[0])
            zmm1[0].o = zmm1[0].o f* 0.5f
            temp0_71[0].o = temp0_71[0].o f+ (temp0_71[0].o
                f* (0x3f000000 - (zmm1[0].o f* (temp0_71[0].o f* temp0_71[0])[0])[0])[0])[0]
            zmm1[0].o = zmm1[0].o f* (temp0_71[0].o f* temp0_71[0])[0]
            zmm1[0].o = 0x3f000000 f- zmm1[0]
            zmm1[0].o = temp0_71[0].o f* zmm1[0]
            zmm1[0].o = temp0_71[0].o f+ zmm1[0]
            arg7[0].o = __vxorps_xmmdq_xmmdq_xmmdq(0xb22bcc77, 0xb22bcc77)
            arg6[0].o = _mm_cmp_ss(arg9[0].o, arg6[0], 2)
            zmm1[0].o = __vblendvps_xmmdq_xmmdq_xmmdq_xmmdq(0x3f800000, zmm1[0].o, arg6[0].o)
            arg6[0].o = zmm0[0].o f* var_240[1]
            temp0_71[0].o = zmm0[0].o f* arg12[0]
            arg6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(temp0_71[0].o, arg6[0].o, 0x10)
            zmm0[0].o = zmm0[0].o f* var_238
            temp0_71[0].o = temp0_32[0].o f* var_230
            zmm5 = temp0_32[0].o f* var_22c
            zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, zmm0[0].o, 0x20)
            arg6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(temp0_71[0].o, zmm5, 0x10)
            temp0_32[0].o = temp0_32[0].o f* var_228
            temp0_71[0].o = zmm1[0].o f* var_220_1.d
            zmm5 = zmm1[0].o f* var_220_1:4.d
            temp0_32[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, temp0_32[0].o, 0x20)
            arg6[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(temp0_71[0].o, zmm5, 0x10)
            zmm1[0].o = zmm1[0].o f* var_220_1:8.d
            arg8[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(arg6[0].o, zmm1[0].o, 0x20)
            zmm1[0].o = _mm_cmp_ps(arg11[0].o, arg14[0].o, 2)
            zmm1[0].o = __vpackssdw_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm0[0].o)
            zmm1[0].o = __vpmovzxwd_xmmdq_xmmq(zmm1[0].q)
            zmm1[0].o = __vpslld_xmmdq_xmmdq_immb(zmm1[0].o, 0x1f)
            arg6 = data_1434431a0
            zmm4 = __vblendvps_ymmqq_ymmqq_memqq_ymmqq(arg6, data_1434430a0, zmm1)
            zmm1[0].o = _mm_permute_ps(zmm4[0].o, 0)
            zmm1 = _mm256_insertf128_ps(zmm1, zmm1[0].o, 1)
            arg9 = _mm256_mul_ps(zmm1, zmm0)
            float temp0_158[0x4] = __vmovshdup_xmmdq_xmmdq(arg9[0].o)
            arg6[0].o = _mm_permute_pd(arg9[0].o, 1)
            var_240[0] = arg9[0].d
            var_240[1] = temp0_158[0]
            var_238 = arg6[0]
            zmm0[0].o = _mm_permute_ps(zmm4[0].o, 0x55)
            zmm0 = _mm256_insertf128_ps(zmm0, zmm0[0].o, 1)
            arg11 = _mm256_mul_ps(zmm0, temp0_32)
            zmm0[0].o = __vmovshdup_xmmdq_xmmdq(arg11[0].o)
            zmm1[0].o = _mm_permute_pd(arg11[0].o, 1)
            var_230 = arg11[0]
            var_22c = zmm0[0]
            var_228 = zmm1[0]
            temp0_32[0].o = _mm_permute_ps(zmm4[0].o, 0xaa)
            zmm11 = _mm256_mul_ps(_mm256_insertf128_ps(temp0_32, temp0_32[0].o, 1), arg8)
            arg8[0].o = __vmovshdup_xmmdq_xmmdq(zmm11[0].o)
            arg12 = data_142fc9300
            float temp0_169[0x8] = _mm256_blend_ps(arg9, arg12, 0xf8)
            arg13 = data_142fc9320
            arg5 = _mm256_and_ps(temp0_169, arg13)
            arg15 = data_1434431c0
            arg5 = _mm256_cmp_ps(arg5, arg15, 2)
            result = zx.q(_mm256_movemask_ps(arg5))
            zmm4[0].o = _mm_permute_pd(zmm11[0].o, 1)
            var_220_1.d = zmm11[0]
            var_220_1:4.d = arg8[0]
            var_220_1:8.d = zmm4[0]
            
            if (result.b == 0xff)
            label_14033c6b0:
                zmm11[0].o = data_142d3f660
                zmm0[0].o = zmm11[0].o
                arg8[0].o = 0x322bcc77
                arg9[0].o = 0x322bcc77
                arg8[0].o = 0xffffffff
            else
                arg5 = _mm256_cmp_ps(_mm256_and_ps(_mm256_blend_ps(arg11, arg12, 0xf8), arg13), 
                    arg15, 2)
                result = zx.q(_mm256_movemask_ps(arg5))
                
                if (result.b == 0xff)
                    goto label_14033c6b0
                
                arg5 = _mm256_cmp_ps(_mm256_and_ps(_mm256_blend_ps(zmm11, arg12, 0xf8), arg13), 
                    arg15, 2)
                result = zx.q(_mm256_movemask_ps(arg5))
                
                if (result.b == 0xff)
                    goto label_14033c6b0
                
                arg5[0].o = arg9[0].o f+ zmm0[0]
                arg5[0].o = zmm4[0].o f+ arg5[0]
                
                if (arg5[0].o f<= arg7[0])
                    zmm0[0].o f- arg9[0].d
                    int64_t r13_1
                    r13_1.b = zmm0[0].o f> arg9[0].d
                    int64_t rax_10 = 0
                    
                    if (zmm0[0].o f> arg9[0].d)
                        rax_10 = 0x14
                    
                    if (zmm4[0].o f> *(&var_240 + rax_10))
                        r13_1 = 2
                    
                    int64_t r14_2 = sx.q(*(&data_14344321c + (r13_1 << 2)))
                    int64_t r12_1 = sx.q(*(&data_14344321c + (r14_2 << 2)))
                    zmm0[0].o = var_240[zx.q((r13_1 * 5).d)]
                    zmm0[0].o = zmm0[0].o f- var_240[sx.q((r14_2 * 5).d)]
                    zmm0[0].o = zmm0[0].o f- var_240[sx.q((r12_1 * 5).d)]
                    zmm1[0].o = 0x3f800000
                    arg5[0].o = 0x3f800000
                    zmm0[0].o = zmm0[0].o f+ 1f
                    zmm0[0].o = __vsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
                    zmm0[0].o = 0x3f800000 f/ zmm0[0]
                    zmm1[0].o = zmm0[0].o f* 0.5f
                    zmm0[0].o = 0x3f800000 f/ zmm0[0]
                    zmm0[0].o = zmm0[0].o f* 0.5f
                    *(&var_1d0 + (r13_1 << 2)) = zmm0[0]
                    zmm0[0].o = var_240[sx.q((r14_2 + (r13_1 << 2)).d)]
                    zmm0[0].o = zmm0[0].o f+ var_240[sx.q((r13_1 + (r14_2 << 2)).d)]
                    zmm0[0].o = zmm0[0].o f* zmm1[0]
                    *(&var_1d0 + (r14_2 << 2)) = zmm0[0]
                    zmm0[0].o = var_240[sx.q((r12_1 + (r13_1 << 2)).d)]
                    zmm0[0].o = zmm0[0].o f+ var_240[sx.q((r13_1 + (r12_1 << 2)).d)]
                    zmm0[0].o = zmm1[0].o f* zmm0[0]
                    arg5[0].o = var_240[sx.q((r12_1 + (r14_2 << 2)).d)]
                    result = sx.q((r14_2 + (r12_1 << 2)).d)
                    arg5[0].o = arg5[0].o f- var_240[result]
                    *(&var_1d0 + (r12_1 << 2)) = zmm0[0]
                    zmm0[0].o = zmm1[0].o f* arg5[0]
                    float var_1c4_1 = zmm0[0]
                    zmm0[0].o = var_1d0
                else
                    zmm0[0].o = 0x3f800000
                    zmm4[0].o = 0x3f800000
                    zmm0[0].o = arg5[0].o f+ 1f
                    zmm0[0].o = __vsqrtss_xmmdq_xmmdq_xmmd(zmm0[0].o, zmm0[0])
                    zmm0[0].o = 0x3f800000 f/ zmm0[0]
                    arg5[0].o = zmm0[0].o f* 0.5f
                    zmm1[0].o = zmm1[0].o f- arg8[0]
                    zmm1[0].o = zmm1[0].o f* arg5[0]
                    arg6[0].o = zmm11[0].o f- arg6[0]
                    arg6[0].o = arg6[0].o f* arg5[0]
                    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg6[0].o, 0x10)
                    arg6[0].o = temp0_158 f- arg11[0]
                    arg5[0].o = arg6[0].o f* arg5[0]
                    zmm1[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, arg5[0].o, 0x20)
                    zmm0[0].o = 0x3f800000 f/ zmm0[0]
                    zmm0[0].o = zmm0[0].o f* 0.5f
                    zmm0[0].o = __vinsertps_xmmdq_xmmdq_xmmdq_immb(zmm1[0].o, zmm0[0].o, 0x30)
                
                arg8[0].o = 0x322bcc77
                arg9[0].o = 0x322bcc77
                arg8[0].o = 0xffffffff
                zmm11[0].o = data_142d3f660
            
            zmm1[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
            arg5[0].o = _mm_permute_pd(zmm1[0].o, 1)
            zmm1[0].o = __vaddps_xmmdq_xmmdq_xmmdq(zmm1[0].o, arg5[0].o)
            arg5[0].o = __vmovshdup_xmmdq_xmmdq(zmm1[0].o)
            zmm1[0].o = zmm1[0].o f+ arg5[0]
            arg5[0].o = _mm_cmp_ss(arg9[0].o, zmm1[0], 6)
            arg5[0].o = __vandnps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg8[0].o)
            arg6[0].o = zmm1[0].o f* 0.5f
            zmm1[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(zmm1[0].o, zmm1[0])
            zmm4[0].o = zmm1[0].o f* zmm1[0]
            zmm4[0].o = zmm4[0].o f* arg6[0]
            zmm4[0].o = 0x3f000000 f- zmm4[0]
            zmm4[0].o = zmm1[0].o f* zmm4[0]
            zmm1[0].o = zmm1[0].o f+ zmm4[0]
            zmm4[0].o = zmm1[0].o f* zmm1[0]
            arg6[0].o = arg6[0].o f* zmm4[0]
            arg6[0].o = 0x3f000000 f- arg6[0]
            arg6[0].o = zmm1[0].o f* arg6[0]
            zmm1[0].o = zmm1[0].o f+ arg6[0]
            zmm1[0].o = _mm_permute_ps(zmm1[0].o, 0)
            zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
            zmm1[0].o = _mm_permute_ps(arg5[0].o, 0)
            zmm0[0].o = __vandps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
            zmm1[0].o = __vandnps_xmmdq_xmmdq_xmmdq(zmm1[0].o, zmm11[0].o)
            zmm0[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm1[0].o)
            zmm1[0].o = __vmovsd_xmmdq_memq(var_220_1:0x10.q)
            zmm1[0].o = __vinsertps_xmmdq_xmmdq_memd_immb(zmm1[0].o, var_220_1:0x18.d, 0x28)
        
        arg5[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, zmm0[0].o)
        arg6[0].o = _mm_permute_pd(arg5[0].o, 1)
        arg5[0].o = __vaddps_xmmdq_xmmdq_xmmdq(arg5[0].o, arg6[0].o)
        arg6[0].o = __vmovshdup_xmmdq_xmmdq(arg5[0].o)
        arg5[0].o = arg5[0].o f+ arg6[0]
        arg6[0].o = _mm_cmp_ss(arg9[0].o, arg5[0], 6)
        arg6[0].o = __vandnps_xmmdq_xmmdq_xmmdq(arg6[0].o, arg8[0].o)
        zmm4[0].o = arg5[0].o f* 0.5f
        arg5[0].o = __vrsqrtss_xmmdq_xmmdq_xmmd(arg5[0].o, arg5[0])
        arg5[0].o =
            arg5[0].o f+ (arg5[0].o f* (0x3f000000 - (arg5[0].o f* arg5[0] f* zmm4[0])[0])[0])[0]
        zmm4[0].o = zmm4[0].o f* (arg5[0].o f* arg5[0])[0]
        zmm4[0].o = 0x3f000000 f- zmm4[0]
        zmm4[0].o = arg5[0].o f* zmm4[0]
        arg5[0].o = arg5[0].o f+ zmm4[0]
        arg5[0].o = _mm_permute_ps(arg5[0].o, 0)
        zmm0[0].o = __vmulps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg5[0].o)
        arg5[0].o = _mm_permute_ps(arg6[0].o, 0)
        zmm0[0].o = __vandps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg5[0].o)
        arg5[0].o = __vandnps_xmmdq_xmmdq_xmmdq(arg5[0].o, zmm11[0].o)
        zmm0[0].o = __vorps_xmmdq_xmmdq_xmmdq(zmm0[0].o, arg5[0].o)
        arg1[rax_1 * 3] = zmm0[0].o
        arg1[rax_1 * 3 + 1] = zmm1[0].o
        arg1[rax_1 * 3 + 2] = arg14[0].o
        rsi_1 += 1
    while (rdi_1 != rsi_1)
arg7[0].o = var_e8
arg8[0].o = var_d8
arg9[0].o = var_c8
arg10[0].o = var_b8
arg11[0].o = var_a8
arg12[0].o = var_88
arg13[0].o = var_78
arg14[0].o = var_68
arg15[0].o = var_58
_mm256_zeroupper()
return result
